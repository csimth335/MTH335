
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">




<link
  href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
  rel="stylesheet">

<style>
.julia {font-family: "Source Code Pro";
        color:#0033CC;
        }
body { padding-top: 60px; }
h5:before {content:"\2746\ ";}
h6:before {content:"\2742\ ";}
pre {display: block;}
</style>

<script src="http://code.jquery.com/jquery.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

<!-- .julia:before {content: "julia> "} -->

<style></style>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


<!-- not TeX-AMS-MML_HTMLorMML-->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG">  
</script>
<script>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ["\$","\$"], ["\\(","\\)"]]
  },
  displayAlign: "left",
  displayIndent: "5%"
});
</script>


<script type="text/javascript">
$( document ).ready(function() {
  $("h1").each(function(index) { 
       var title = $( this ).text()
       $("#page_title").html("<strong>" + title + "</strong>");
       document.title = title
  });
  $( "h2" ).each(function( index ) {
    var nm =  $( this ).text();                                    
    var id = $.trim(nm).replace(/ /g,'');
    this.id = id
    $("#page_dropdown").append("<li><a href='#" + id + "'>" + nm + "</a></li>");
  });
  $('[data-toggle="popover"]').popover();  
});
</script>

</head>


<body data-spy="scroll" >

<nav class="navbar navbar-default  navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
         
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="#" id="page_title"></a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
         <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
           Jump to... <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu" id="page_dropdown"></ul>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<header>
</header>

<div class="container-fluid">
  <div class="span10 offset1">
<h1>Numeric integration based on interpolation.</h1><p>The process of integration has an <em>easy</em> answer: $\int_a^b f(x) dx = F(b) - F(a)$ <em>when</em> you can find an antiderivative $F$. But that isn't always the case.</p><blockquote>
<p>The <a href="https://en.wikipedia.org/wiki/Risch_algorithm">Risch algorithm</a> characterizes when an <em>elementary</em> function has an antiderivative of a specific form.  The original problem is posed by Liouville. Not all elementary functions (functions obtained by composing exponentials, logarithms, radicals, trigonometric functions, and the four arithmetic operations (+ − × ÷)) are integrable. For example, $f(x) = \exp(x^2)$.</p>
</blockquote><h2>What to do when you can't find an antiderivative?</h2><p>We can approximate an integral a few ways. First, if we approximate $f$ by $g$, then $\int_a^b f(x) dx \approx \int_a^b g(x) dx$.</p><p>For example, if we approximate $\sin(x)$ by its Taylor polynomial of degree $5$ we get an approximation.</p><pre class="sourceCode julia">using Roots
using Polynomials
f(x) = sin(x)
x = poly([0.0])
g = sum([ D(f,k)(0)*x^k / factorial(k) for k in 0:5])
[g, polyint(g)]</pre>
<pre class="output">
2-element Array{Polynomials.Poly{Float64},1}:
 Poly(1.0*x - 0.166667*x^3 + 0.00833333*x^5)   
 Poly(0.5*x^2 - 0.0416667*x^4 + 0.00138889*x^6)</pre>

<p>Integrating over $[0,\pi]$ gives an exact answer of 2. This one approximates via:</p><pre class="sourceCode julia">diff(map(x->polyval(polyint(g), x), [0, pi]))</pre>
<pre class="output">
1-element Array{Float64,1}:
 2.21135</pre>

<p>Not so close!</p><p>The Taylor series isn't the best approximation over an interval, rather it is good near a point, in this case $c=0$.</p><pre class="sourceCode julia">using Plots
plot([f, x -> polyval(g, x)], 0, pi)</pre>
    <div id="125696b4-2161-4ccd-96f8-542bc70f3acf" style="width:600px;height:400px;"></div>
    <script>
    PLOT = document.getElementById('125696b4-2161-4ccd-96f8-542bc70f3acf');
    Plotly.plot(PLOT, [{"showlegend":true,"mode":"lines","xaxis":"x","colorbar":{"title":""},"line":{"color":"rgba(0, 154, 250, 1.000)","shape":"linear","dash":"solid","width":1},"y":[0.015339511014701464,0.03067541242093728,0.17166717434870798,0.3092109495508594,0.38905360195643246,0.4660711028717981,0.528569798326157,0.5883242430613824,0.64976343137182,0.7072222201480519,0.7563636858789748,0.8015668055511774,0.8453874952692148,0.88414893600324,0.9224276439123988,0.953297448140898,0.9743114618127554,0.9891442673157648,0.9969893076459937,0.999969950348809,0.9976603433323025,0.9895650509231215,0.9756317894726576,0.955973171617894,0.9277136899890839,0.892799925717166,0.8536308148768001,0.8089183002652021,0.7568615568015717,0.699491362414812,0.6473736431477508,0.5920349014277694,0.44512104927186746,0.2949169869941366,0.03991632077017152],"type":"scatter","name":"y1","yaxis":"y","x":[0.015340112644426933,0.030680225288853866,0.17252171697354257,0.31436320865823125,0.39960403291889857,0.48484485717956594,0.5569148892483315,0.6289849213170972,0.7072731766942932,0.7855614320714894,0.8577362788103786,0.9299111255492679,1.0072901891756778,1.0846692528020878,1.1743204864101577,1.2639717200182279,1.3436431565239784,1.423314593029729,1.4931792632139245,1.5630439333981199,1.639215177553415,1.71538642170871,1.7920103724793233,1.8686343232499367,1.9533518991288894,2.038069475007842,2.11867611078605,2.1992827465642577,2.2830949451205087,2.3669071436767597,2.437459162487701,2.508011181298642,2.6802832177626836,2.8422240131314496,3.1016657253491733]},{"showlegend":true,"mode":"lines","xaxis":"x","colorbar":{"title":""},"line":{"color":"rgba(227, 111, 71, 1.000)","shape":"linear","dash":"solid","width":1},"y":[0.030675412420942356,0.3092110096676083,0.4660723484522798,0.5883319284669571,0.6497808761586655,0.7072585374155731,0.7564307693029837,0.801684689126639,0.845593342442877,0.8844937399188665,0.9230271346626385,0.9542977416262005,0.9758415258568157,0.991427286657274,1.0001732790582354,1.0043422393821217,1.0037403960673696,0.9978916341076183,0.9868964262522322,0.971016241111002,0.9481408265455626,0.9201697846429002,0.8893752555572255,0.8551209698810402,0.7759552027445169,0.7056542136502948,0.6635724374713655,0.6238430018746416,0.590054539350293,0.5611775133729703,0.5426307483492475,0.529084405288722,0.5214446237851065,0.5206701403130787,0.5212243276115256,0.5219687899756136,0.5229073630372536],"type":"scatter","name":"y2","yaxis":"y","x":[0.030680225288853866,0.31436320865823125,0.48484485717956594,0.6289849213170972,0.7072731766942932,0.7855614320714894,0.8577362788103786,0.9299111255492679,1.0072901891756778,1.0846692528020878,1.1743204864101577,1.2639717200182279,1.3436431565239784,1.423314593029729,1.4931792632139245,1.5630439333981199,1.639215177553415,1.71538642170871,1.7920103724793233,1.8686343232499367,1.9533518991288894,2.038069475007842,2.11867611078605,2.1992827465642577,2.3669071436767597,2.508011181298642,2.5941471995306626,2.6802832177626836,2.7612536154470666,2.8422240131314496,2.9070844411858805,2.9719448692403114,3.0368052972947424,3.1016657253491733,3.1116474574093282,3.121629189469483,3.131610921529638]}], {"showlegend":true,"xaxis":{"tickvals":[1.0,2.0,3.0],"ticks":"inside","tickmode":"array","domain":[0.05100612423447069,0.9934383202099737],"linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"","tickangle":0,"titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgba(0, 0, 0, 1.000)","ticktext":["1","2","3"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"anchor":"y"},"paper_bgcolor":"rgba(255, 255, 255, 1.000)","annotations":[],"height":400,"margin":{"l":0,"b":20,"r":0,"t":20},"plot_bgcolor":"rgba(255, 255, 255, 1.000)","yaxis":{"tickvals":[0.2,0.4,0.6000000000000001,0.8,1.0],"ticks":"inside","tickmode":"array","domain":[0.03762029746281716,0.9901574803149606],"linecolor":"rgba(0, 0, 0, 1.000)","showgrid":true,"title":"","tickangle":0,"titlefont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":15},"tickcolor":"rgba(0, 0, 0, 1.000)","ticktext":["0.2","0.4","0.6","0.8","1.0"],"zeroline":false,"type":"-","tickfont":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"anchor":"x"},"legend":{"bordercolor":"rgba(0, 0, 0, 1.000)","bgcolor":"rgba(255, 255, 255, 1.000)","font":{"color":"rgba(0, 0, 0, 1.000)","family":"sans-serif","size":11},"y":1.0,"x":1.0},"width":600});
    </script>
<h3>Polynomial interpolation</h3><p>We discussed that there exists a unique polynomial of degree $n$ or less that goes through the points $(x_i, f(x_i))$ for $i=0, 1, \dots, n$. We gave a formula in terms of <em>divided differences</em>. This is due to Newton. Lagrange gave an alternate form. Let</p>$$~
l_i(x) = \prod_{j=0, j\neq i}^n \frac{x - x_j}{x_i-x_j}.
~$$
<p>Then, $p(x) = \sum_0^n f(x_i)l_i(x)$ so for $n+1$ points chosen in $[a,b]$ we have</p>$$~
\int_a^b f(x) dx \approx \int_a^b p(x) dx = \int_a^b \sum f(x_i) l_i(x) dx = \sum f(x_i) \int_a^b l_i(x) dx.
~$$
<p>If $A_i = \int_a^b l_i(x) dx$, then we have the integral is approximately $\sum A_i f(x_i)$. (The $A_i$ do not depend on $f$, so could in theory be pre-computed.)</p><blockquote>
<p>A <a href="https://en.wikipedia.org/wiki/Newton&#37;E2&#37;80&#37;93Cotes_formulas">Newton-Cotes</a> formula is one where the $x_i$ are equally spaced over $[a,b]$.</p>
</blockquote><p>Issues here are related to the approximating polynomials getting squirrelly out near the ends of the interval (Runge phenomenon).</p><h2>Riemann integration</h2><p>Consider the easiest case $x_0$ some point in $[a,b]$. Then we have the approximate integral: $f(x_0)(b-a)$.</p><p>What is the error? We know that the error using $n+1$ points is $f(x) - p(x) = f^{(n+1)}(\xi_x)/(n+1)! (x-x_0)\cdots(x-x_n)$, so in this case we have:</p>$$~
\begin{align}
\int_a^b f(x) dx - \int_a^b p(x) &=
\int_a^b (f(x) - p(x)) dx\\
&= \int_a^b f'(\xi_x)(x-x_0) dx\\
&\approx f'(\xi) \frac{(x-x_0)^2}{2} \mid_a^b
\end{align}
~$$
<p>If we were to take $x_0 = a$, then this becomes $f'(\xi)(b-a)^2/2$. So it depends on the length of the interval and the derivative.</p><h2>Trapezoid rule</h2><p>Now suppose, $x_0=a, x_1=b$. So $n=1$. Then we have the trapezoid rule. We have then</p>$$~
l_0(x) = \frac{b-x}{b-a}, \quad \text{ and } l_1(x) = \frac{x-a}{b-a}
~$$
<p>And $A_0 = A_1 = (b-a)/2$.</p><p>So, $\int_a^b f(x) dx \approx f(x_0)A_0 + f(x_1) A_1 = (b-a)/2 \cdot (f(a)  + f(b))$. The formula for the trapezoid.</p><p>To compute the error, we have $f(x) - p(x) = f''(\xi_x)/2 (x-a)(x-b)$. Is we write:</p>$$~
\int_a^b (f(x) - p(x))dx  = -\int_a^b  f''(\xi_x)/2 (x-a)(x-b) dx = -f''(\xi) \int_a^b (x-a)(x-b)/2 dx = -f''(\xi) (b-a)^3/12.
~$$
<p>Again, the error depends on the length of the integral cubed. </p><h3>The more familiar trapezoid rule:</h3><p>Take the partition $a=x_0 < x_1 < \cdots < x_{n-1} < x_n = b$ and apply the trapezoid rule to each pair. This will give an approximation formula. Suppose $x_i = a + (b-a)/n \cdot i$. Then the formulas become:</p>$$~
\int_a^b f(x) dx \approx \frac{h}{2}(f(a) + 2 \sum_{i=1}^{n-1} f(a + ih) + f(b)), \quad h=(b-a)/2.
~$$
<p>The errors add to give:</p>$$~
\text{error } = -\sum_i^n f''(\xi_i) h^3/12 \approx -nf''(\xi) h^3/12 =- f''(\xi) \frac{(b-a)^3}{12n^2}.
~$$
<h2>Simpson's rule</h2><p>Using the points $a = x_0 < x_1 < x_2=b$ with $x_1$ the midpoint, yields Simpson's rule.</p><p>The approximation becomes:</p>$$~
\int_a^b f(x) dx = \frac{b-a}{6}(f(a) + 4f(\frac{a+b}{2}) + f(b))
~$$
<p>With error, $-1/90 \cdot ((b-a)/2)^5 f^{(4)}(\xi)$.</p><p>If we apply over an equally spaced partition, the errors accumulate to yield</p>$$~
\text{Simpson's error} = -\frac{1}{180} \frac{(b-a)^5}{n^4} f^{(4)}(\xi)
~$$
<h3>Compare.</h3><p>We can numerically compare these errors.</p><pre class="sourceCode julia">riemann(f, a,b) = f(a)*(b-a)
trapezoid(f,a,b) = 1/2 * (b-a)*(f(b)  + f(a))
simpson(f, a, b) = (b-a)/6*(f(a) + 4f((a+b)/2) + f(b))</pre>
<pre class="output">
simpson (generic function with 1 method)</pre>

<p>Let's look at $f(x) = e^x$ between $0$ and $\log(2)$ with an answer of $e^{log(2)} - e^0 = 2 - 1 = 1$.</p><pre class="sourceCode julia">n = 10
a,b = 0, log(2)
xs = linspace(a, b, n+1)
xis = zip(xs[1:end-1], xs[2:end])
f(x) = exp(x)


r = sum([riemann(f, xi, xi1) for (xi,xi1) in xis])
t = sum([trapezoid(f, xi, xi1) for (xi,xi1) in xis])
s = sum([simpson(f, xi, xi1) for (xi,xi1) in xis])

[r-1 t-1 s-1]</pre>
<pre class="output">
1×3 Array{Float64,2}:
 -0.034257  0.000400345  8.01396e-9</pre>

<h2>Change of variables</h2><p>If we have a formula to approximate $\int_c^d f(x) dx$ then we can do a linear $u$-substitution to integrate over $[a,b]$. The transform is</p>$$~
u(t) = \frac{b-a}{d-c}t + \frac{ad - bc}{d-c}
~$$
<p>And then</p>$$~
\int_a^b f(x) dx = \frac{b-a}{d-c}\int_c^d f(u(t)) dt.
~$$
<p>It is conventional to use $a=-1, b=1$.</p><h2>Weight functions</h2><p>The Newton-Cotes formulas can be generalized to handle integrals with weight functions:</p>$$~
\int_a^b f(x) w(x) dx \approx \int_a^b \sum f(x_i) l_i(x) w(x) dx = \sum f(x_i) \int_a^b l_i(x) w(x) = \sum f(x_i) A_i.
~$$
<p>As before, only with the weight function defining $A$. Again, the $A_i$ do not depend on $x$. If we have $a,b=-1,1$, then they only depend on how the $x_i$ are chosen.</p><h3>Choosing the $x_i$ differently</h3><p>Integrating the general error term and assuming $|f^{(n+1)}(\xi) | \leq M$ we have</p>$$~
| \int_a^b f(x) dx - \sum A_i f(x_i)| \leq \frac{M}{(n+1)!}  \int_a^b \prod|x - x_i| dx.
~$$
<p>Some choice of $x_i$ will <em>minimize</em> this product.</p><p>Claim: For $a=-1, b=1$, the following will minimize:</p>$$~
x_i = \cos(\frac{(i+1)\pi}{n+2}), \quad 0 \leq i \leq n.
~$$
<p>Let's investigate:</p><pre class="sourceCode julia">using Interact, Plots

xs = linspace(-1,1, 251)
f(xs) =  x -> prod([abs(x-xi) for xi in xs])

@manipulate for x0=xs, x1=xs, x2=xs, x3=xs
vs = [x0,x1,x2,x3]
v = quadgk(f(vs), -1, 1)[1]
plot(f(vs), -1, 1)
title!(string(v))
end</pre>
<p>How to compare:</p><pre class="sourceCode julia">n = 3
i = 0:n
cos.((i+1)*pi/(n+2))</pre>
<pre class="output">
4-element Array{Float64,1}:
  0.809017
  0.309017
 -0.309017
 -0.809017</pre>

<p>These values are the zeros of the function</p>$$~
U_{n+1}(x) = \frac{\sin((n+2)\theta)}{\sin(\theta)}, \quad x = \cos(\theta).
~$$
<p>These functions are polynomials in $x$! Called the Chebyshev polynomials of the second kind.</p><p>They have leading coefficient $2^{n+1}$, as</p>$$~
\int_{-1}^1 |\prod (x-x_i)| dx = 2^{-n}
~$$
<p>With these nodes, one can minimize the error bound to get:</p>$$~
|\text{error}| \leq \frac{M}{(n+1)! 2^n}.
~$$
<blockquote>
<p>Thm (p487): For monic polynomials $p$ of degree $n$, the Chebyshev polynomials minimize $\int_{-1}^1 |p(x)| dx$.</p>
</blockquote>
  </div>
</div>  

</body>
</html>
