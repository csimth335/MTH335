
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">




<link
  href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
  rel="stylesheet">

<style>
.julia {font-family: "Source Code Pro";
        color:#0033CC;
        }
body { padding-top: 60px; }
h5:before {content:"\2746\ ";}
h6:before {content:"\2742\ ";}
pre {display: block;}
</style>

<script src="http://code.jquery.com/jquery.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

<!-- .julia:before {content: "julia> "} -->

<style></style>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


<!-- not TeX-AMS-MML_HTMLorMML-->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG">  
</script>
<script>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ["\$","\$"], ["\\(","\\)"]]
  },
  displayAlign: "left",
  displayIndent: "5%"
});
</script>


<script type="text/javascript">
$( document ).ready(function() {
  $("h1").each(function(index) { 
       var title = $( this ).text()
       $("#page_title").html("<strong>" + title + "</strong>");
       document.title = title
  });
  $( "h2" ).each(function( index ) {
    var nm =  $( this ).text();                                    
    var id = $.trim(nm).replace(/ /g,'');
    this.id = id
    $("#page_dropdown").append("<li><a href='#" + id + "'>" + nm + "</a></li>");
  });
  $('[data-toggle="popover"]').popover();  
});
</script>

</head>


<body data-spy="scroll" >

<nav class="navbar navbar-default  navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
         
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="#" id="page_title"></a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
         <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
           Jump to... <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu" id="page_dropdown"></ul>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<header>
</header>

<div class="container-fluid">
  <div class="span10 offset1">
<h1>linear algebra review</h1><h2>systems of equations and matrices</h2><p>In Chapter 3 our problem was methods to solve $f(x) = 0$ where $f:R \rightarrow R$. Of course, this also handles problems of the type $f(x) = g(x)$ and $f(x) = b$.</p><p>In Chapter 4 we begin with <strong>linear</strong> systems of equations:</p>$$~
\begin{align}
a_{11} x_1 + a_{12}x_2 + \cdots a_{1n} x_n &= b_1\\
a_{21} x_1 + a_{22}x_2 + \cdots a_{2n} x_n &= b_2\\
&\vdots\\
a_{m1} x_1 + a_{m2}x_2 + \cdots a_{mn} x_n &= b_m
\end{align}
~$$
<p>A solution is a set of values $x_1, x_2, \dots, x_n$ so that each equation is true simultaneously.</p><h3>Matrix</h3><p>We see three sets of numbers: the $a$s, the $b$s and the $x$s. We represent these as matrices:</p>$$~
A = \left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1n}\\
a_{21} & a_{22} & \cdots & a_{2n}\\
 & \vdots &  & \\
a_{m1} & a_{m2} & \cdots & a_{mn}\\
\end{array}
\right)
~$$
$$~
x = \left(
\begin{array}{c}
x_1\\
x_2\\
\vdots\\
x_n
\end{array}
\right)
~$$
$$~
b = \left(
\begin{array}{c}
b_1\\
b_2\\
\vdots\\
b_n
\end{array}
\right)
~$$
<h3>Why?</h3><p>This is because matrices have their own, nearly familar, algebra that allows us to represent the system of equations in terms of an equation:</p>$$~
Ax = b.
~$$
<p>Here are two main problems in linear algebra that repeat themselves all the time:</p><ul>
<li><p>Solve for $x$ in $Ax = b$. Also, somewhat related, if $Ax = b$ has no solutions, can we find "best" solutions?</p>
</li>
<li><p>Solve for the $\lambda$ for which $Ax = \lambda x$ has non-zero solutions</p>
</li>
</ul><h2>Example:</h2><p>Consider the system of equations is</p>$$~
\begin{align}
1x_{11} + 2x_{12} + 3x_{13} &= 4\\
5x_{21} + 6x_{22} + 7x_{23} &= 8\\
9x_{31} + 10x_{32} + 11x_{33} &= 12
\end{align}
~$$
<p>Then we can do the following:</p><pre class="sourceCode julia">A = [1 2 3; 5 6 7; 9 10 11]
b = [4,8,12]
A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1   2   3
 5   6   7
 9  10  11</pre>

<p>and</p><pre class="sourceCode julia">b</pre>
<pre class="output">
3-element Array{Int64,1}:
  4
  8
 12</pre>

<p>To put in <em>variables</em> we can use symbolic math:</p><pre class="sourceCode julia">using SymPy
x = [symbols("x$i") for i in 1:3]</pre>
<div class="well well-sm">
\begin{bmatrix}x_{1}\\x_{2}\\x_{3}\end{bmatrix}</div>

<p>And from here:</p><pre class="sourceCode julia">A*x - b</pre>
<div class="well well-sm">
\begin{bmatrix}x_{1} + 2 x_{2} + 3 x_{3} - 4\\5 x_{1} + 6 x_{2} + 7 x_{3} - 8\\9 x_{1} + 10 x_{2} + 11 x_{3} - 12\end{bmatrix}</div>

<h3>Notation</h3><p>We saw $A$ has $m$ rows and $n$ columns.</p><p>Here we can view $x$ and $b$ as <em>vectors</em> or as matrices with 1 column. This is an identification, they are not mathematically the same thing.</p><h4>A matrix is a vector! A vector is not a matrix!</h4><p>A basic matrix in <code>Julia</code> is stored in contiguous memory, so has an order. Here we can see what it is  by looking at the first 4 elements</p><pre class="sourceCode julia">A[1:4]</pre>
<pre class="output">
4-element Array{Int64,1}:
 1
 5
 9
 2</pre>

<p>A vector on the other hand is not stored as a matrix in this sense:</p><pre class="sourceCode julia">isa(b, Matrix)</pre>
<pre class="output">
false</pre>

<p>This is because <code>b</code> has only 1 dimension, a matrix has two. This is different from the "row vector" and "column vector""</p><pre class="sourceCode julia">A[1,:]</pre>
<pre class="output">
3-element Array{Int64,1}:
 1
 2
 3</pre>

<pre class="sourceCode julia">A[:, 1:1]</pre>
<pre class="output">
3×1 Array{Int64,2}:
 1
 5
 9</pre>

<p>But note this is similar  – but different. How?</p><pre class="sourceCode julia">A[:,1]</pre>
<pre class="output">
3-element Array{Int64,1}:
 1
 5
 9</pre>

<h3>+, -, *,/</h3><p>We can add and subtract matrices of the same size. The result is a matrix $(a_{ij} - b_{ij})$.</p><pre class="sourceCode julia">A = [1 2 3; 4 5 6; 7 8 9]
B = [1 4 7; 2 5 8; 3 6 9]
A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  2  3
 4  5  6
 7  8  9</pre>

<p>and</p><pre class="sourceCode julia">B</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  4  7
 2  5  8
 3  6  9</pre>

<p>And here we have:</p><pre class="sourceCode julia">A-B</pre>
<pre class="output">
3×3 Array{Int64,2}:
 0  -2  -4
 2   0  -2
 4   2   0</pre>

<pre class="sourceCode julia">B-A</pre>
<pre class="output">
3×3 Array{Int64,2}:
  0   2  4
 -2   0  2
 -4  -2  0</pre>

<h4>Multiplication</h4><p>Multiplication is possible for matrices, but the size constraint is different: $A B$ is defined if the number of columns of $A$ matches the number of rows of $B$. That is if $A$ is $m \times n$ then $B$ must be $n \times p$ for some $m$ and $p$.</p><p>The defintion is $(AB)_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + \cdots + a_{in}b_{nj}$.</p><pre class="sourceCode julia">A * B</pre>
<pre class="output">
3×3 Array{Int64,2}:
 14   32   50
 32   77  122
 50  122  194</pre>

<p>If we think of $A = [a_1; a_2; \cdots; a_m]$ as comprised of <em>row</em> vectors and $B = [b_1 b_2 \cdots b_p]$ as <em>column</em> vectors, then we have the $ij$ terms is the product $a_i \cdot b_j$. If we identify these row and column vectors as just vectors, this is the dot product.</p><pre class="sourceCode julia">A[1, :] * B[:, 2]</pre>
<pre class="output">
DimensionMismatch("Cannot multiply two vectors")
</pre>

<pre class="sourceCode julia">(A*B)[1, 2]</pre>
<pre class="output">
32</pre>

<p>Though matrix multiplication is defined and uses the same notation as multiplication of numbers, it doesn't have two key properties:</p><ul>
<li><p>It is not – in general – commutative. That is $AB \neq BA$ except in special cases:</p>
</li>
</ul><pre class="sourceCode julia">A*B - B*A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 -52  -46  -40
 -46  -16   14
 -40   14   68</pre>

<ul>
<li><p>There is no cancellation property. That is if $A\cdot B=0$ is need not be that $B$ or $A$ must be $0$.</p>
</li>
</ul><pre class="sourceCode julia">C = [1 0 0;-2 0 0; 1 0 0]</pre>
<pre class="output">
3×3 Array{Int64,2}:
  1  0  0
 -2  0  0
  1  0  0</pre>

<p>So $C$ is non-zero, $A$ is non-zero, and yet:</p><pre class="sourceCode julia">A*C</pre>
<pre class="output">
3×3 Array{Int64,2}:
 0  0  0
 0  0  0
 0  0  0</pre>

<h4>Division</h4><p>We don't have "division" defined for matrices. There are for some <em>square</em> matrices an analog, $A^{-1}$ for which $AA^{-1} = I$, the matrix with a one on the diagonal. This is sort of like $a \cdot (1/a) = 1$ when $a \neq 0$.</p><p>There is a built in function like division <code>\</code>. The expression <code>A \ b</code> will be a solution, <code>x</code> to <code>Ax &#61;b</code>:</p><pre class="sourceCode julia">A * (A \ b)  - b</pre>
<pre class="output">
3-element Array{Float64,1}:
  0.0        
 -8.88178e-16
  0.0        </pre>

<h3>The transpose</h3><p>The transpose of the matrix $A=(a_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$ is found by swapping rows and columns:</p>$$~
A^T = (a_{ji})_{1 \leq i \leq m, 1 \leq j \leq n}
~$$
<p>On the computer we see easily using <code>.&#39;</code> for transpose:</p><p>Here is $A$:</p><pre class="sourceCode julia">A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  2  3
 4  5  6
 7  8  9</pre>

<p>and its transpose</p><pre class="sourceCode julia">A.'</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  4  7
 2  5  8
 3  6  9</pre>

<p>The transpose is an <em>involution</em> – meaning do it twice and you haven't changed anything:</p><pre class="sourceCode julia">(A.').'</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  2  3
 4  5  6
 7  8  9</pre>

<p>Without a "dot" the conjugate transpose is performed. For real-valued matrices the two are identical:</p><pre class="sourceCode julia">A'</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  4  7
 2  5  8
 3  6  9</pre>

<hr /><p>A matrix is <em>symmetric</em> if $A^T = A$. This means $A$ needs to be square and have symmetry along its main diagonal.</p><p>Our example <code>A</code> is <em>not</em> symmetric:</p><pre class="sourceCode julia">A' - A</pre>
<pre class="output">
3×3 Array{Int64,2}:
  0   2  4
 -2   0  2
 -4  -2  0</pre>

<p>However, in general $A^TA$ is symmetric:</p><pre class="sourceCode julia">B = A'*A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 66   78   90
 78   93  108
 90  108  126</pre>

<p>We could see visually, or confirm as follows</p><pre class="sourceCode julia">B' - B</pre>
<pre class="output">
3×3 Array{Int64,2}:
 0  0  0
 0  0  0
 0  0  0</pre>

<h2>positive definite</h2><p>A matrix $A$ is <em>positive definite</em> if for every nonzero vector $x$, $x^T A x > 0$.</p><p>The example in the book is</p><pre class="sourceCode julia">A = [2 1; 1 2]</pre>
<pre class="output">
2×2 Array{Int64,2}:
 2  1
 1  2</pre>

<p>For which $x^T A x = (x_1 + x_2)^2 + x_1^2 + x_2^2 > 0$ (if $x \neq 0$).</p><h2>Inverses</h2><p>Let $I$ be an $n \times n$ <em>identify matrix</em>,  that is $I$ is all $0$s with $1$s on the diagonal:</p><p>Then$AI = A$ and  $IA = A$, if defined. For example:</p>$$~
(AI)_{ij}
= a_{i1} I_{1j} + \cdots+ a_{ij} I_{jj} + \cdots + a_{in} I_{nj}
= a_{i1} 0+ \cdots+ a_{ij} 1+ \cdots + a_{in} 0
= a_{ij}
~$$
<p>Let $A$ be given (and $m \times n$) Then $B$ is a <em>right inverse</em> if $AB = I$.</p><blockquote>
<p>Thm: A <em>square</em> matrix, $A$, can possess at most one right inverse.</p>
</blockquote><p>Proof: a linear algebra proof that rests on a fact: a linear combination of a <em>basis</em> producing $x$ is unique.</p><p>Suppose $B$ is an inverse. We aim to show $B$ is unique. The product</p>$$~
(AB)_{\cdot k} = \sum_l a_{\cdot l} b_{lk}
~$$
<p>So if we look at the $k$th column vector of a matrix and write this as $A_{:k}$, then:</p>$$~
I_{:k} = \sum_l b_{lk}A_{:l}
~$$
<p>So the $k$th column vector of $I$ is a linear combination of the column vectors of $A$. This means the columns of $A$ span the same space as the columns of $I$, which is $R^n$. So the columns of $A$ form a basis for $R^n$, ans so the values $b_{lk}$ are uniquely defined.</p><blockquote>
<p>Theorem: If $A$ and $B$ are square matrices, then a right inverse is a left inverse.</p>
</blockquote><p>Suppose $B$ is a right inverse ($AB=I$). Then set $C = BA - I + B$ and note: $AC = ABA - AI + AB = A(BA) - A + I = I$, so $C=B$ and consequently $BA = I$ as well.</p><p>So, if a square matrix $A$ has a $n\times n$ right inverse it has a unique inverse and is called invertible. When it exists, the inverse is written $A^{-1}$.</p><h3>How to find an inverse?</h3><p>We return to system of equations. There we know a few basic facts:</p><ul>
<li><p>we could interchange the order in how we define our equations and we would have the same answers</p>
</li>
<li><p>we could replace one equation by its multiple by a <strong>non</strong>-zero constant and would still have the same answers</p>
</li>
<li><p>we could replace one equation by adding another to it and not effect the solutions.</p>
</li>
</ul><p>The latter is on the only tricky one. If we use $E'_i = E_i + E_j$ instead, do we get a difference?</p><p>Well, if our solutions solved $E_i$ and $E_j$, then it would also solve $E'_I$, as $0 + 0$ is still $0$. To get the reverse, the solution makes <em>both</em> $E'_i$ and $E_j$ $0$, so $-E_j$ is $0$, and then so is $E_i = $E'_i - E_j$.</p><h3>Matrix equivalence</h3><p>As systems of linear equations lend them selves to matrices, so to do elementary operations lend themselves to matrix operations.</p><p>To illustrate:</p><pre class="sourceCode julia">A = [1 2 3; 4 5 6; 7 8 9]</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  2  3
 4  5  6
 7  8  9</pre>

<p>We can switch rows 2 and 3 via let multiplication of the identity matrix with rows $2$ and $3$ swapped</p><pre class="sourceCode julia">[1 0 0; 0 0 1; 0 1 0] * A</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  2  3
 7  8  9
 4  5  6</pre>

<p>We can multiply row 2 as follows:</p><pre class="sourceCode julia">[1 0 0; 0 pi 0; 0 0 1] * A</pre>
<pre class="output">
3×3 Array{Float64,2}:
  1.0      2.0     3.0   
 12.5664  15.708  18.8496
  7.0      8.0     9.0   </pre>

<p>We can replace row $2$ with row $2$ plus row $3$ via:</p><pre class="sourceCode julia">[1 0 0; 0 1 0; 0 1 1] * A</pre>
<pre class="output">
3×3 Array{Int64,2}:
  1   2   3
  4   5   6
 11  13  15</pre>

<p>If we think of these elementary operations in terms of left multiplication by an elementary matrix, we can write the transformed matrix as $E_m E_{m-1} \cdots E_2 E_1 A$.</p><blockquote>
<p>Thm: If $A$ is invertible, we can find $A^{-1}$ from a sequence of elementary row operations.</p>
</blockquote><p>Idea: If we can find a sequence such that $E_m E_{m-1} \cdots E_2 E_1 A = I$, the $E_m E_{m-1} \cdots E_2 E_1 \cdot I = A^{-1}$. Why?</p>$$~
A^{-1}A = (E_m E_{m-1} \cdots E_2 E_1 \cdot I) A
= E_m E_{m-1} \cdots E_2 E_1 (I \cdot A)
= E_m E_{m-1} \cdots E_2 E_1 \cdot A
= I.
~$$
<h3>Nonsingular matrix properties</h3><p>For an $n \times n$ matrix $A$, all of these are equivalent:</p><ul>
<li><p>The matrix $A$ is nonsingular</p>
</li>
<li><p>The <em>determinant</em> of $A$ is non-zero</p>
</li>
<li><p>The rows of $A$ for a basis for $R^n$</p>
</li>
<li><p>The columns of $A$ for a basis for $R^n$</p>
</li>
<li><p>The equation $Ax=0$ is only satisfied by $x=0$.</p>
</li>
<li><p>The equation $Ax=b$ has only one solution, $x$.</p>
</li>
<li><p>The matrix $A$ is a product of elementary matrices</p>
</li>
<li><p>The value $0$ is not an eigenvalue of $A$.</p>
</li>
</ul><h2>Block multiplication</h2><p>Matrices can be partitioned into blocks. So for example:</p><pre class="sourceCode julia">B = [1 2; 3 4]
C = [5 6; 6 5]
O = [0 0; 0 0]
I = [1 0; 0 1]

A = [B C; O I]</pre>
<pre class="output">
4×4 Array{Int64,2}:
 1  2  5  6
 3  4  6  5
 0  0  1  0
 0  0  0  1</pre>

<p>Problem 7 has one show that $A^k$ is also a block matrix with blocks $B^k$ and $(B^k-I)(B-I)^{-1}C$ to go with O and I. Let's see with k = 2:</p><p>We need $B-I$ to have an inverse. We check:</p><pre class="sourceCode julia">det(B-I)</pre>
<pre class="output">
-6.0</pre>

<p>Now let $k=3$, we have</p><pre class="sourceCode julia">k = 3
out = A^k</pre>
<pre class="output">
4×4 Array{Int64,2}:
 37   54  117  114
 81  118  252  243
  0    0    1    0
  0    0    0    1</pre>

<p>And now check the pieces:</p><pre class="sourceCode julia">out[1:2, 1:2] ==B^k</pre>
<pre class="output">
true</pre>

<p>and</p><pre class="sourceCode julia">(B^k - I)* inv(B-I) * C == out[1:2, 3:4]</pre>
<pre class="output">
true</pre>


  </div>
</div>  

</body>
</html>
