
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">




<link
  href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
  rel="stylesheet">

<style>
.julia {font-family: "Source Code Pro";
        color:#0033CC;
        }
body { padding-top: 60px; }
h5:before {content:"\2746\ ";}
h6:before {content:"\2742\ ";}
pre {display: block;}
</style>

<script src="http://code.jquery.com/jquery.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

<!-- .julia:before {content: "julia> "} -->

<style></style>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


<!-- not TeX-AMS-MML_HTMLorMML-->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG">  
</script>
<script>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ["\$","\$"], ["\\(","\\)"]]
  },
  displayAlign: "left",
  displayIndent: "5%"
});
</script>


<script type="text/javascript">
$( document ).ready(function() {
  $("h1").each(function(index) { 
       var title = $( this ).text()
       $("#page_title").html("<strong>" + title + "</strong>");
       document.title = title
  });
  $( "h2" ).each(function( index ) {
    var nm =  $( this ).text();                                    
    var id = $.trim(nm).replace(/ /g,'');
    this.id = id
    $("#page_dropdown").append("<li><a href='#" + id + "'>" + nm + "</a></li>");
  });
  $('[data-toggle="popover"]').popover();  
});
</script>

</head>


<body data-spy="scroll" >

<nav class="navbar navbar-default  navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
         
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="#" id="page_title"></a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
         <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
           Jump to... <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu" id="page_dropdown"></ul>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<header>
</header>

<div class="container-fluid">
  <div class="span10 offset1">
<h1>Norms and the analysis of errors</h1><p>Consider the task of walking in New York City. We need to go 3 blocks over and 4 blocks up? How far do we need to walk?</p><ul>
<li><p>As the "crow flies" the answer is easy: $\sqrt{3^2 + 4^2}$.</p>
</li>
<li><p>as you end up walking, the answer is easy: $3 + 4$</p>
</li>
<li><p>if you need to know the farthest you go in any one direction, the answer is just the larger of $3$ and $4$.</p>
</li>
</ul><p>The point is, you might answer "distance" in different manners.</p><h2>Vector norms</h2><p>Let $V$ be a vector space.</p><p>Define a <em>norm</em>  as a function, $\| \cdot \|$, from $V$ to non-negative reals if it obeys:</p><ul>
<li>$\| x \| > 0$
<p>if $x \neq 0$.</p>
</li>
<li>$\| \lambda x\| = |\lambda| \| x\|$
<p>for real $\lambda$ and $x \in V$.</p>
</li>
<li>$\|x + y \| \leq \| x\| + \| y \|$
<p>. (The triangle inequality)</p>
</li>
</ul><h3>Examples</h3><p>The familiar Euclidean distance is a norm where</p>$$~
\| x \| = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}.
~$$
<p>We also have others:</p><ul>
<li><p>The city walking norm:</p>
</li>
</ul>$$~
\| x \| = |x_1| + |x_2| + \cdots + |x_n|
~$$
<ul>
<li><p>The max distance in any direction norm:</p>
</li>
</ul>$$~
\| x\| = max_i |x_i|
~$$
<p>In fact, for any $p \geq 1$, we can define the $p$-norm by:</p>$$~
\| x \|_p = (x_1^p + x_2^p + \cdots + x_n^p)^{1/p}.
~$$
<p>With this, we have the $2$-norm, the $1$-norm and the limiting $\infty$-norm.</p><pre class="sourceCode julia">x = [1,2,3]
norm(x, 2)  # default so just norm(x) works too</pre>
<pre class="output">
3.7416573867739413</pre>

<pre class="sourceCode julia">norm(x, 1)</pre>
<pre class="output">
6.0</pre>

<p>and</p><pre class="sourceCode julia">norm(x, Inf)</pre>
<pre class="output">
3.0</pre>

<blockquote>
<p>It is customary to call these the $l_2$, $l_1$ and $l_\infty$ norms.</p>
</blockquote><h3>The unit ball</h3><p>With a  norm, we can define sets. Such as the set of points within a "distance" of $1$ of $x$. Call this the unit ball about $x$:</p>$$~
B_1(x) = \{ y : \| y - x\| \leq 1 \}
~$$
<p>We could define this for any size $\delta$, and would use the notation $B_\delta(x)$ for that.</p><h2>Matrix norms</h2><p>A norm is a general thing and can be defined for matrices and other objects. A special case of matrix norms are those induced by a vector norm.</p><p>If we consider all vectors $u$ with $\| u \| = 1$, then we can map these vectors under a matrix $A$ to a new set of vectors $Au$. How big are these? If we were to focus on the largest, we would consider</p>$$~
\sup \{ \| Au \|: u \in V, \| u\| = 1 \}.
~$$
<p>This will vary depending on $A$ – If $A$ is a rotation, the lengths won't change so we will get $1$ our. If $A$ is a dilation, then some vectors will get stretched, so this would typically be different from $1$.</p><p>Define the <em>matrix norm</em> induced by the vector norm $\| \cdot \|$ to be the value of this supremum:</p>$$~
\| A\| = \sup \{ \| Au \|: u \in V, \| u\| = 1 \}.
~$$
<h3>This defines a norm</h3><blockquote>
<p>Thm (p188) This matrix norm is a norm.</p>
</blockquote><p>We have if $A$ is non-zero, then there is some $v$ with $Av \neq 0$ and if we consider $v/\|v\|$ some unit vector with $Av \neq 0$. Hence $\| A \| \geq \|Av\| > 0$></p><p>If $\lambda$ is non zero, the since $\| \lambda v\| = |\lambda| \| v\|$, it will also be true that:</p>$$~
\{ \| \lambda Au \|: u \in V, \| u\| = 1 \} = \{ |\lambda|\| Au \|: u \in V, \| u\| = 1 \}
~$$
<p>and so the $\lambda$ can come outside.</p><p>Finally, we consider the triangle inequality and show it is inherited. We need to consider two matrices (of the same size):</p>$$~
\begin{align}
\| A + B \|
&= \sup \{ \| (A+B)u \|: \|u \| = 1\}\\
&\leq \sup \{ \| Au \| + \|Bu \|: \|u \| = 1\}\\
&\leq \sup \{ \| Au \|  : \|u \| = 1\} + \sup \{ \| Bu \|  : \|u \| = 1\}\\
&\|A\| + \|B\|.
\end{align}
~$$
<blockquote>
<p>Corollary:</p>
</blockquote>$$~
\| Ax \| \leq \|A \| \cdot \| x\|.
~$$
<blockquote>
<p>Corollary. If $A$ and $B$ are of the appropriate size, then</p>
</blockquote>$$~
\| A B \| \leq \| A \| \cdot \| B\|.
~$$
<p>(Why? For unit $x$ we have: $\| (AB)x\| = \|A (Bx)\| \leq \| A\| \cdot \| Bx\| \leq \|A\| \cdot \| B \| \cdot \|x \|$.)</p><h3>Can we identify these norms</h3><blockquote>
<p>Thm. (p287) The norm induced by the $2$-norm is the largest singular value.</p>
</blockquote><p>(A singular value is an eigen value of $A^T A$.)</p><blockquote>
<p>Thm. (p189) The norm induced by the $\infty$-norm is</p>
</blockquote>$$~
\|A \|_\infty = \max_{1 \leq i \leq n} \sum_{j=1}^n | a_{ij}|
~$$
<p>That is, take the $l_1$ norm for each row vector and find the largest value</p><blockquote>
<p>Thm. The $||A||_1$ norm is found by taking the $l_1$ norm of each column vector and finding the largest.</p>
</blockquote><h2>Condition number</h2><p>Consider $Ax=b$.</p><p>We wish to quantify when a matrix might give issues, beginning with two examples, the first when the matrix is slightly perturbed, the second when the target vector $b$ is.</p><h3>perturbed matrix</h3><p>The inequalities $\| Ax\| \leq \|A\| \|x\|$ and $\|AB\| \leq \|A\| \|B\|$ are widely used. For ezample, Suppose we are considering $Ax=b$. One solution would be to form the inverse and write $x = A^{-1} b$. The compuation is not always possible though, so we might end up with $B \approx A^{-1}$. Then we have $\tilde{x} = Bb$. What can we say about how far apart $x$ and $\tilde{x}$ are?</p>$$~
\| x - \tilde{x} \| = \| x - Bb \| = \|x - BAx\| = \|(I - BA)x\| \leq \|I - BA\| \|x\|.
~$$
<p>So the <em>relative error</em> is bounded by:</p>$$~
\frac{\| x - \tilde{x} \| } {\|x\|} \leq \|I - BA\|.
~$$
<p>If the relative error is big for small pertubations, then the problem is unstable.</p><h3>perturbed target vector</h3><p>Suppose $A$ is invertible and we wish to solve $Ax=b$, but instead have a perturbed value for $b$, $\tilde{b}$. (Which might happen solving via a $LU$ decomposition). Then we get values $x$ and $\tilde{x}$ which satisfy $Ax = b$ and $A\tilde{x} = \tilde{b}$. How close are the $x$'s?</p>$$~
\| x - \tilde{x}\| - \| A^{-1}b - A^{-1} \tilde{b}\| = \| A^{-1}(b-\tilde{b}) \| \leq
\| A^{-1}\| \|b - \tilde{b}\|.
~$$
<p>To get a sense of the <em>relative error</em>, we continue by multiplying and dividing by $\|b\|$ on the right-hand side:</p>$$~
\| x - \tilde{x}\|  \leq
\| A^{-1}\| \|b\| \frac{ \|b - \tilde{b}\| }{\|b\|}
= \| A^{-1}\|  \cdot  \|Ax\| \cdot \frac{ \|b - \tilde{b}\|} {\|b\|}
\leq \| A^{-1}\| \cdot \|A\| \cdot  \|x\| \frac{ \|b - \tilde{b}\|}{\|b\|}.
~$$
<p>Dividing by $\|x\|$ gives the relative error in $x$ is bounded by $\|A^{-1}\| \cdot \|A\|$ times the relative error in the $b$.</p><h3>Condition number</h3><p>The <em>condition number</em> of a matrix is given by</p>$$~
\kappa(A) = \|A \| \cdot \|A^{-1}\|.
~$$
<p>Example,</p><pre class="sourceCode julia">A = [1 1 1; 2 2 5; 4 6 8]</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  1  1
 2  2  5
 4  6  8</pre>

<p>What is the condition number? For the $l_\infty$ norm, we have the row sums, $\sum_j |a_{ij}|$ are $3,9, 18$, so $18$ is $\|A\|_\infty$. We can show that $A^{-1} = (1/6) B$, where</p><pre class="sourceCode julia">B = [14 2 -3;  -4 -4 3; -4 2 0]</pre>
<pre class="output">
3×3 Array{Int64,2}:
 14   2  -3
 -4  -4   3
 -4   2   0</pre>

<p>The largest row sum is $14 + 2 +3 = 19$. So the  $l_\infty$ norm of the inverse is $1/6 \cdot 19$. This gives a condition number of:</p><pre class="sourceCode julia">18 * 19 /6</pre>
<pre class="output">
57.0</pre>

<p>Which we can check with</p><pre class="sourceCode julia">cond(A, Inf)</pre>
<pre class="output">
57.0</pre>

<h4>l_1 norm</h4><p>Had we done the $l_1$ norm, we only need to take columns instead of rows. For that we see:</p>$$~
\|A\|_1 = 14, \quad \|A^{-1}\| = (1/6) \cdot (14 + 4 + 4), \quad \text{and } \kappa(A) = 14 \cdot22 /6 = 51~1/3.
~$$
<p>This is confirmed by</p><pre class="sourceCode julia">cond(A, 1)</pre>
<pre class="output">
51.33333333333333</pre>

<h4>l_2 norm</h4><p>Finally, we note that the $l_2$ norms for $A$ and $A^{-1}$ can be found with:</p><pre class="sourceCode julia">B = inv(A)
sqrt(maximum(eigvals(B'*B))) * sqrt(maximum(eigvals(A'*A)))</pre>
<pre class="output">
32.164266119208776</pre>

<p>Which can be verified</p><pre class="sourceCode julia">cond(A, 2)</pre>
<pre class="output">
32.16426611920866</pre>

<h3>Example, a matrix with a large condition number</h3><p>Consider the matrix</p>$$~
A = \left[
\begin{array}{cc}
1 & 1 + \epsilon\\
1 - \epsilon & 1
\end{array}
\right].
$$~

As the book points out, this has inverse

$$~
A^{-1}= \frac{1}{\epsilon^2} \cdot
\left[
\begin{array}{cc}
1 & -1 - \epsilon\\
-1 + \epsilon & 1
\end{array}
\right].
$$~

For small $\epsilon>0$, we can read off the $l_\infty$ norms. We have $l_2(A) =2 + \epsilon$ and
$l_2(A^{-1}) = \epsilon^{-2} (2 + \epsilon)$. This means

$$~
\kappa(A) = \frac{(2+\epsilon)^2}{\epsilon^2} \approx 4 \epsilon^{-2}.
~$$
<p>So for small $\epsilon$, this can be large.</p><pre class="sourceCode julia">ep = 1e-2
A = [1 1+ep; 1-ep 1]
cond(A, Inf)</pre>
<pre class="output">
40401.00000000445</pre>

<h4></h4><p>To see an example, let $b = [3.02, 2.99]$ and $\tilde{b} = [3,3]$. The relative error is small</p><pre class="sourceCode julia">b = [3.02, 2.99]; bt = [3,3]
norm(b - bt, Inf)/norm(b, Inf)</pre>
<pre class="output">
0.006622516556291397</pre>

<p>But solving yields two values quite a distance apart</p><pre class="sourceCode julia">x, xt = A \ b, A \ bt</pre>
<pre class="output">
([1.0, 2.0], [-300.0, 300.0])</pre>

<p>And these have a relative error of:</p><pre class="sourceCode julia">norm(x-xt, Inf) / norm(x, Inf)</pre>
<pre class="output">
150.4999999996815</pre>

<p>Here a small change in $b$ led to a <em>large</em> change in determining $x$. Such a matrix is called <strong>ill conditioned</strong>.</p><h2>More notation</h2><p>Suppose $Ax = b$ and $A\tilde{x} = \tilde{b}$. Define</p><ul>
<li><p>the <em>residual vector</em> $r = b - A\tilde{x} = b - \tilde{b}$.</p>
</li>
<li><p>the <em>error vector</em> $e=x - \tilde{x}$.</p>
</li>
</ul><p>Then we have this relationship between their norms, given the condition number:</p>$$~
\frac{1}{\kappa(A)} \frac{\|r\|}{\|b\|}
\leq
\frac{\|e\|}{\|b\|}
\leq
\kappa(A) \frac{\|r\|}{\|b\|}.
~$$

  </div>
</div>  

</body>
</html>
