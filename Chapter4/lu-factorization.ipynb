{
  "cells": [
     {"cell_type":"markdown","source":"<h1>LU Factorization</h1>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Return to the task of solving a system of equations:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n\\begin{align}\na_{11} x_1 + a_{12}x_2 + \\cdots a_{1n} x_n &= b_1\\\\\na_{21} x_1 + a_{22}x_2 + \\cdots a_{2n} x_n &= b_2\\\\\n&\\vdots\\\\\na_{m1} x_1 + a_{m2}x_2 + \\cdots a_{mn} x_n &= b_m\n\\end{align}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Which we wrote as $Ax=b$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Easy to solve systems</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>If we have equations resulting in $A$ being a diagonal matrix, then we have basically:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n\\begin{align}\na_{11}x_1 &= b_1\\\\\na_{22}x_2 &= b_2\\\\\n& \\vdots\\\\\na_{nn}x_n &= b_n\n\\end{align}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>This has <em>easy</em> solutions, namely. If $a_{ii} \\neq 0$, then $x_i = b_i/a_{ii}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>If an $a_{ii} = 0$, then the determinant of $A$ is $0$, and there is not a unique solution.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Lower triangular matrices</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>If $A$ is <em>lower triangular</em>, that is ($a_{ij} = 0$ if $j > i$) or:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA = \\left(\n\\begin{array}{cccc}\na_{11} & 0 & \\cdots & 0\\\\\na_{21} & a_{22} & \\cdots & 0\\\\\n & \\vdots &  & \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\\\\\n\\end{array}\n\\right)\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Then we can solve recursively</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul>\n<li><p>First, we solve $a_{11} x_1 = b_1$ with $x_1 = b_1 / a_{11}$.</p>\n</li>\n<li><p>Next we solve $a_{21}x_1 + a_{22}x_2 = b_2$ by first subsititution in for our just-solved $x_1$, and then solving:</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{21}x_1 + a_{22}x_2 = b_2\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{21} ( b_1 / a_{11})+ a_{22}x_2 = b_2\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_2 = (b_2 - a_{21}(b_1/a_{11})) / a_{22}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<ul>\n<li><p>repeat. In general we have</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_i = (b_i - \\sum_{j=1}^{i-1} a_{ij} x_j) \\cdot \\frac{1}{a_{ii}}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>It is important that we have $a_{ii} \\neq 0$, as otherwise we will have issues dividing. But this will be the case if $det(A) \\neq 0$. (Why?)</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>This method is called <em>forward substitution</em></p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Upper triangular matrices</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>A matrix $U$ is <em>upper triangular</em> if $u_{ij} = 0$ if $i < j$. For example:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA = \\left(\n\\begin{array}{cccc}\na_{11} & a_{12} & \\cdots & a_{1, n-1} & a_{1n}\\\\\n0 & a_{22} & \\cdots & a_{2,n-1} &a_{2n}\\\\\n&&\\vdots&&\\\\\n0 & 0 &\\cdots & a_{n-1,n-1} & a_{n-1,n}\\\\\n0 & 0 &\\cdots & 0 & a_{nn}\\\\\n\\end{array}\n\\right)\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Then solving $Ax=b$ can be done by working <em>backwards</em>:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_n = b_n / a_{nn}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>and from here:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_{n-1} = (b_{n-1} - a_{n-1, n}x_n)/a_{n-1, n-1} = (b_{n-1} - a_{n-1, n}) \\cdot b_n / a_{nn}/a_{n-1, n-1}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>And in general</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_i = (b_i - \\sum_{j=i+1}^n a_{ij} x_j) / a_{ii}.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Again, we need $a_{ii} = 0$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Permuted L or U matrices</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Consider</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA = \\begin{array}{ccc}\n1 & 2 & 3\\\\\n0 & 0 & 4\\\\\n0 & 5 & 6\n\\end{array}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Clearly if we permuted rows 2 and 3 this would be upper triangular, so we could solve easily by: first solving row 2, then use that to solve row 3 and then finally row 1.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Define $p = [p_1, p_2, \\cdots, p_n]$,  to be a permutation vector if the mapping $i \\rightarrow p_i$ maps the set $1, \\dots, n$ to itself in a bijective manner <em>and</em> the matrix $(\\alpha_{ij}) = (a_{p_i j})$ is either upper or lower triangular.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>(In the above we would have $p_1 = 1, p_2 = 3$, and $p_3 = 2$.)</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Then clearly we could solve the permuted system of equations. For example, in the case that we end up lower triangular, so that forward substitution works, we would have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nx_i = (b_{p_i} -  \\sum_{j=1}^{i-1} a_{p_i j}) / a_{p_i i}.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<h2>Why bother?</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Suppose we knew that $A=LU$, then we can solve $Ax = b$ easily by:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul>\n<li><p>solve the  equatulation $Ly = b$ for $y$.</p>\n</li>\n<li><p>But $y = Ux$, so we solve $Ux = y$ for $x$.</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>So if we can <em>factorize</em> $A = LU$, we can easily solve $Ax = b$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Example</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>In Julia (and MATLAB) there is a built in solver for these problems:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2Ã—2 Array{Int64,2}:\n 1  2\n 0  1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U = [1 2; 0 1]"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2-element Array{Float64,1}:\n -5.0\n  3.0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["b = [1, 3]\nx = U \\ b"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2-element Array{Float64,1}:\n 0.0\n 0.0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U*x - b"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>In fact, there are many different methods depending on assumptions. For example, rationals:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2-element Array{Rational{Int64},1}:\n -5//1\n  3//1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U = [1//1 2; 0 1]\nU \\ b"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>There are special methods for many others...</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Can we find LU for a given A?</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Suppose $A = LU$, then we have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{ij} = l_{i1} u_{1j} + l_{i2} u_{2j} + \\cdots l_{in} u_{nj}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>But:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul>\n<li><p>lower triangular means $l_{ij} = 0$ if $j > i$</p>\n</li>\n<li><p>upper triangular means $u_{ij} = 0$ is $j < i$.</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>So</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{ij} = \\sum_{s = 1}^{min(i, j)} l_{is} u_{sj}.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Now to prove we can find $LU = A$. We will do so by  induction. Suppose we know the first $k-1$ columns of $L$ and the first $k-1$ rows of $U$. We then have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{kk} = \\sum_{s=1}^{min(k,k)} \\cdot = \\sum_{s=1}^k \\cdot = \\sum_{s=1}^{k-1} l_{ks}u_{sk} + l_{kk} u_{kk}.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>The first part of the right hand sum involves columns of $L$ for which $s < k$ and rows of $U$ or which $s < k$. So all values are known by our assumption. So if $l_{kk}$ is known (say assumed to 1 or some other non-zero value) we can solve for $u_{kk}$ in terms of known values. To be explicit:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nu_{kk} = (a_{kk} - \\sum_{s=1}^{k-1} l_{ks}u_{sk} ) / l_{kk}.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Then to fill out the $k$ row of $U$, we consider for $j > k$ (for which $min(j,k) = l$):</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{kj} = \\sum_{s=1}^{k-1} l_{ks} u_{sj} + l_{kk} u_{kj}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>The sum is of known values and $l_{kk}$ is known, so for each $j$, as specified, we can solve for $u_{kj}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Similarly, for the $k$ column of $L$, we consider for $j > k$</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{jk} = \\sum_{s=1}^{k-1} l_{js} u_{sk} + l_{jk} u_{kk}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>As before, the sum is known, and here, so is $u_{kk}$, so we can solve for $l_{jk}$ when $j > k$. That is we can fill in the $k$ column.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Special cases</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<ul>\n<li><p>If we always were to take $l_{ii} = 1$ we get Dolittle's factorization</p>\n</li>\n<li><p>If we always were to take $u_{ii} = 1$ we get Crout's factorization</p>\n</li>\n<li><p>If we take $u_{ii} = l_{ii}$ we get Cholesky's factorization.</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Example</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Let's look at this matrix</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Int64,2}:\n 1  1  1\n 1  2  2\n 1  2  3"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["A = [1 1 1; 1 2 2; 1 2 3]"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>We need to fill in $U$ and $L$. We start with a zeros:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Int64,2}:\n 0  0  0\n 0  0  0\n 0  0  0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L = zero(A)\nU = zero(A)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Now we fill in: we have $1 = a_{11} = l_{11} u_{11}$ so we can take each to be 1:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L[1,1] = 1\nU[1,1] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Then for $U$ we need to fill in $u_{12}$ and $u_{23}$. For these we have</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{12} = 1 = (0) +  l_{11} u_{12} = 1 u_{12}, \\quad\na_{13} = 1 = (0) + l_{11} u_{13} = 1 u_{13}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>So both are 1:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U[1,2] = 1\nU[1,3] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And for the first row of $L$ we have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{21} = 1 = (0) + l_{21}u_{11} = l_{21}, \\quad\na_{31} = 1 = (0) + l_{31}u_{11} = l_{31}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>So ditto:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L[2,1] = 1\nL[3,1] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Moving on to $k=2$ gives first the diagonal terms:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{22} = (l_{21} u_{12}) + l_{22} u_{22}, \\quad\\text{or}\n2 = (1 \\cdot 1) + l_{22} u_{22}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>We can take both to be $1$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L[2,2] = 1\nU[2,2] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And to fill in for $j > 2$:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{23} = 2 = (l_{21} u_{13}) + l_{22}u_{23} = (1\\cdot 1) + 1 u_{23},\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>So $u_{23} = 1$</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U[2,3] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And from</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{32} = 2 = (l_{31} u_{12}) + l_{32} u_{22} = (1 \\cdot 1) + l_{32} \\cdot 1\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>So $l_{32} = 1$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L[3,2] = 1"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Finally, we need to find the last diagonal terms:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{33} = 3 = (l_{31}u_{13} + l_{32}u_{23}) + l_{33} u_{33} = (1\\cdot 1 + 1\\cdot 1) +  l_{33} u_{33}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>So we can take each to be $1$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L[3,3] = 1\nU[3,3] = 1"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Int64,2}:\n 1  0  0\n 1  1  0\n 1  1  1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>and</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Int64,2}:\n 1  1  1\n 0  1  1\n 0  0  1"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And we verify:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Int64,2}:\n 0  0  0\n 0  0  0\n 0  0  0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["A - L*U"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Optimized versions</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>There are built in functions for these:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["([1.0 0.0 0.0; 1.0 1.0 0.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 0.0 1.0 1.0; 0.0 0.0 1.0], [1, 2, 3])"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["L, U, p =  lu(A)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>We already verified that $LU = A$ for this $A$. The <code>p</code> is a permulation vector. In general, we should verify</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["3Ã—3 Array{Float64,2}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["A[p,:]  -  L * U"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h2>When do we know this will work?</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Define the $k$th leading principal minor of $A$ to be the submatrix $a_{ij}$ for $1 \\leq i,j \\leq k$. Call this $A_k$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<blockquote>\n<p>Thm: If $A$ is $n \\times n$ and all $n$ leading principle minors are non-singular, then $A$ has an LU decomposition</p>\n</blockquote>","metadata":{}},
{"cell_type":"markdown","source":"<p>Proof. Suppose by induction this is true for step $k-1$. The we have $A_{k-1}$ can be factored: $A_{k-1} = L_{k-1} U_{k-1}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>We wish to find $L_k$ and $U_k$ which are extensions and satisfy $A_k = L_k U_k$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Consider the case $1 \\leq i \\leq k-1$ and</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{ik} = \\sum_{s = 1}^{k-1} l_{is}u_{sk}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>We know the $a_{ik}$, the $l$'s involved are from $L_{k-1}$. The $u$'s we don't know (yet), but as $L_{k-1}$ is non-singular we can solve for the $u$s and this is just of the form $b = L_{k-1} x$. So we can fill out the value of $U_k$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Similarly, for $1 \\leq j \\leq k-1$ we have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{kj} = \\sum_{s=1}^{k-1} l_{ks} u_{sj}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>This is of the form $b = U_{k-1} x$ so can be solved to fill out the value of $L_k$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>FInally, we need to solve for $l_{kk}$ and $u_{kk}$, but we have:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\na_{kk} = \\sum_s^{k-1} l_{ks} u_{sk} + l_{kk}u_{kk}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>If the value of $l_{kk} = 1$, then $u_{kk}$ can be solved as the sum is now known. That is, we can fill out $L_k$ and $U_k$ with $A_k = L_k U_k$, as desired.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Cholesky factorization</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>We know the transpose of a lower triangular matrix is upper and vice versa. This gives hope to a factorization of the form $A = L L^T$, known as the Cholesky factorization. When is this possible?</p>","metadata":{}},
{"cell_type":"markdown","source":"<blockquote>\n<p>Thm: If $A$ is real, symmetric and positive definite then it has a unque factorization $A=LL^T$ and $L$ has a positive diagonal.</p>\n</blockquote>","metadata":{}},
{"cell_type":"markdown","source":"<p>Pf: We must have $Ax=0$ has only a solution $x=0$, as positive definite means $x^T A x > 0$ for non-zero $x$. By considering vectors of the form $x = [x_1 x_2 \\cdot x_k 0 0 \\cdots 0]$ we can see that $A_k$ will also be non-singular.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>So by the last theorem $A= LU$ for some $L$ and $U$. But $A^T = A$ so $LU = (LU)^T = U^T L^T$. Multiplying on the right and left as follows gives</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n\\begin{align}\nL^{-1} (L U) (L^T)^{-1} &=L^{-1} U^T L^T (L^T)^{-1}\\\\\nU (L^T)^{-1} &= L^{-1} U^T.\n\\end{align}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>The left side is upper triangular, the right side lower triangular, hence the must be a diagonal matrix $D$: $D = U (L^T)^{-1}$ and so  $L D = (LU)(L^T)^{-1} = A(L^T)^{-1}$, giving $A = L D L^T$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>If we can show that $D$ has all positive diagonal terms, then we can define $D^{1/2}$ by $(\\sqrt{d_{ii}})$ and express $A$ as $(LD^{1/2}) (LD^{1/2})^T$ which is what we want.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>So, why do we know $D$ has all positive diagonal terms? Because $D$ is positive definite:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Take $x$ and then:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n\\begin{align}\nx^T D x &= x^T (L^{-1}) A (L^T)^{-1} x\\\\\n&= (x^T L^{-1}) A ((L^T)^{-1} x)\\\\\n&= ((L^{-1})^Tx)^T A ((L^T)^{-1}x)\\\\\n&= ((L^{-1})^Tx)^T A ((L^{-1})^{t}x)\n&> 0.\n\\end{align}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>The last line as $A$ is positive definite and $(L^{-1})^Tx$ is non-zero. The fact we can swap out the inverse and transpose of a matrix is something to prove.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Proof take 2</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Here is an alternative <a href=\"http://www.math.iit.edu/~fass/477577_Chapter_7.pdf\">proof</a>, perhaps more instructive. It requires a few facts about matrices which are symmetric and positive definite:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul>\n<li><p>If $A$ is then $a_{11} > 0$.</p>\n</li>\n<li><p>If $A$ is then any sub matrix formed by removing row $i$ and column $i$ will be</p>\n</li>\n<li><p>If $A$ is and $L$ has full rank, then $LAL^T$ is one.</p>\n</li>\n</ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>Suppose we have $A$ as assumed. Then we can write $A$ in the following way where $a_{11} > 0$.</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA = \\left[\n\\begin{array}{cc}\na_{11} & w^T\\\\\nw & K\n\\end{array}\n\\right]\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>By the second fact above, $K$ Is symmetric and positive definite.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Now consider the following lower triangular matrix:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nL_1 = \\left[\n\\begin{array}{cc}\n\\sqrt{a_{11}} & 0\\\\\n\\frac{w}{\\sqrt{a_{11}}} & I\n\\end{array}\n\\right]\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Then using block matrix multiplication we get this decomposition: $A = L B L^T$ where</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nB_1= \\left[\n\\begin{array}{cc}\nI & 0^T\\\\\n0 & K - \\frac{ww^T}{a_{11}}\n\\end{array}\n\\right].\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<hr />","metadata":{}},
{"cell_type":"markdown","source":"<p>To see:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/latex":["\\begin{bmatrix}a_{11}&w\\\\w&K\\end{bmatrix}"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["using SymPy\nw, K= symbols(\"w,  K\", real=true)\nw = [w]\t # a vector\na_11 = symbols(\"a_11\", positive=true)\nA = [a_11 w'; w K]\nL = [sqrt(a_11) 0; w*(1/sqrt(a_11)) 1]\nB_1 = [1 0;0 (K-w*w'*(1/a_11))]\n\nL*B_1*L'"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<hr />","metadata":{}},
{"cell_type":"markdown","source":"<p>Let $A_1 =  K - ww^T / a_{11}$. Since $A$ is positive definite and $L$ has full rank (why?) it must be $B_1$ is positive definite. Hence, $A_1$ is too. But both $K$ and $ww^T$ are symmetric, so $A_1$ is also symmetric and positive definite.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>So we can find $M_2$, $B_2$, such that $A_1 = M_2 B_2 M_2^T$ and $B_2$ will have a symmetric, positive definite submatrix $A_2$. As written $M_2$ is $n-1 \\times n-1$. We embed this into</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nL_2 =  \\left[\n\\begin{array}{cc}\nI & 0^T\\\\\n0 & M_2\n\\end{array}\n\\right].\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>And then $A = L_1 L_2 A_2 L_2^T L_1^T$ where</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA_2 = \\left[\n\\begin{array}{cc}\nI_2 & 0^T\\\\\n0   & K_2\n\\end{array}\n\\right].\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>We see were this repeated, we would eventually get:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\nA = L_1 L_2 \\cdots L_n \\cdot I \\cdot  L_n^T \\cdots L_2^T L_1^T.\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>Letting $L = L_1 L_2 \\cdots L_n$ yields the result, $A=LL^T$, after noting the the product of lower triangular matrices is lower triangular.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Example</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>This comes from statistics. Consider the <em>overdetermined</em> system:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["4Ã—2 Array{Int64,2}:\n 1  2\n 3  5\n 4  7\n 1  8"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["A = [1 2; 3 5; 4 7; 1 8]"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["4-element Array{Int64,1}:\n 1\n 2\n 3\n 4"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["b = [1,2,3,4]"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>The system $Ax=b$ has no solutions. However, this system will:</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n(A^T A) x = A^T b\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>(Assuming $A^TA$ is non-singular, we have it is symmetric and positive definite.)</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2Ã—2 Array{Int64,2}:\n 27   53\n 53  142"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["M = A' *A"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>So we can take the cholesky decomposition:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2Ã—2 UpperTriangular{Float64,Array{Float64,2}}:\n 5.19615  10.1999 \n  â‹…        6.16141"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["U = chol(M)'   # default answer is upper triangular\nL = U'"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>So we can solve $LL^Tx = A^T b$. First we solve for $y$ in $Ly=A^Tb$ with:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2-element Array{Float64,1}:\n -16.282 \n  10.5495"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["y = L \\ (A'*b)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And then solve $L^Tx = y$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2-element Array{Float64,1}:\n -3.13347\n  6.89947"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["x = L' \\ y"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>This answer is not the \"answer\" (as that doesn't exist):</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["4-element Array{Float64,1}:\n  9.66548\n 23.097  \n 32.7624 \n 48.0623 "]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["A*x - b"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>However, it has a property: it is the <code>x</code> with the smallest difference:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["63.3265770219158"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["norm(A*x - b)"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["10-element Array{Float64,1}:\n 1.73083\n 1.91261\n 2.29206\n 3.6014 \n 4.42797\n 4.69364\n 4.78943\n 5.97877\n 7.71382\n 8.13918"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sort([norm(A*rand(2) - b) for _ in 1:10])"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Why?</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>(P279) Suppose $Ax=b$ has $A$ being $m \\times n$ with $m > n$ and $rank(A) = n$. Then, this will typically have no solutions. In that case, what is sought is a best solution in the sense of minimizing $\\| b - Ax \\|_2$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Now suppose $x$ solves $A^TAx=A^Tb$, and $y$ is some other value, then</p>","metadata":{}},
{"cell_type":"markdown","source":"\n$$\n\\begin{align}\n\\|b - Ay\\|_2^2 &= \\|b - Ax + A(x-y)\\|_2^2\\\\\n&= (b - Ax + A(x-y))^T \\cdot  (b - Ax + A(x-y))\\\\\n&= (b - Ax)^T\\cdot (b-Ax) + (b-Ax)^T\\cdot (A(x-y)) + (A(x-y))^T \\cdot (b-Ax) + (A(x-y)^T) \\cdot (A(x-y))\\\\\n&= \\| b - Ax \\|_2^2 + 0 + 0 + \\|A(x-y)\\|_2^2\\\\\n&\\geq  \\| b - Ax \\|_2^2\n\\end{align}\n$$\n","metadata":{}},
{"cell_type":"markdown","source":"<p>The latter because, $Ax-b$ has a $0$ dot product with vectors in the column space of $A$ (as $A^T(Ax-b)=0$. But $A(x-y)$ is in the column space of $A$. (Any $Az = [A_{\\cdot 1} ; A_{\\cdot 2} ; \\cdots ; A_{\\cdot n}] \\cdot z = z_1A_{\\cdot 1} + z_2A_{\\cdot 2} + \\cdots + z_n A_{\\cdot n}$.) So, the cross terms are 0 and the result holds.</p>","metadata":{}}
    ],
 "metadata": {
  "language_info": {
   "file_extension": ".jl",                                                                                                             
   "mimetype": "application/julia", 
   "name": "julia",
   "version": "0.6"
  },
 "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  }

 },
 "nbformat": 4,
 "nbformat_minor": 2

}
