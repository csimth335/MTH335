
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">




<link
  href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
  rel="stylesheet">

<style>
.julia {font-family: "Source Code Pro";
        color:#0033CC;
        }
body { padding-top: 60px; }
h5:before {content:"\2746\ ";}
h6:before {content:"\2742\ ";}
pre {display: block;}
</style>

<script src="http://code.jquery.com/jquery.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

<!-- .julia:before {content: "julia> "} -->

<style></style>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


<!-- not TeX-AMS-MML_HTMLorMML-->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG">  
</script>
<script>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ["\$","\$"], ["\\(","\\)"]]
  },
  displayAlign: "left",
  displayIndent: "5%"
});
</script>


<script type="text/javascript">
$( document ).ready(function() {
  $("h1").each(function(index) { 
       var title = $( this ).text()
       $("#page_title").html("<strong>" + title + "</strong>");
       document.title = title
  });
  $( "h2" ).each(function( index ) {
    var nm =  $( this ).text();                                    
    var id = $.trim(nm).replace(/ /g,'');
    this.id = id
    $("#page_dropdown").append("<li><a href='#" + id + "'>" + nm + "</a></li>");
  });
  $('[data-toggle="popover"]').popover();  
});
</script>

</head>


<body data-spy="scroll" >

<nav class="navbar navbar-default  navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
         
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="#" id="page_title"></a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
         <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
           Jump to... <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu" id="page_dropdown"></ul>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<header>
</header>

<div class="container-fluid">
  <div class="span10 offset1">
<h1>LU Factorization</h1><p>Return to the task of solving a system of equations:</p>$$~
\begin{align}
a_{11} x_1 + a_{12}x_2 + \cdots a_{1n} x_n &= b_1\\
a_{21} x_1 + a_{22}x_2 + \cdots a_{2n} x_n &= b_2\\
&\vdots\\
a_{m1} x_1 + a_{m2}x_2 + \cdots a_{mn} x_n &= b_m
\end{align}
~$$
<p>Which we wrote as $Ax=b$.</p><h2>Easy to solve systems</h2><p>If we have equations resulting in $A$ being a diagonal matrix, then we have basically:</p>$$~
\begin{align}
a_{11}x_1 &= b_1\\
a_{22}x_2 &= b_2\\
& \vdots\\
a_{nn}x_n &= b_n
\end{align}
~$$
<p>This has <em>easy</em> solutions, namely. If $a_{ii} \neq 0$, then $x_i = b_i/a_{ii}$.</p><p>If an $a_{ii} = 0$, then the determinant of $A$ is $0$, and there is not a unique solution.</p><h3>Lower triangular matrices</h3><p>If $A$ is <em>lower triangular</em>, that is ($a_{ij} = 0$ if $j > i$) or:</p>$$~
A = \left(
\begin{array}{cccc}
a_{11} & 0 & \cdots & 0\\
a_{21} & a_{22} & \cdots & 0\\
 & \vdots &  & \\
a_{m1} & a_{m2} & \cdots & a_{mn}\\
\end{array}
\right)
~$$
<p>Then we can solve recursively</p><ul>
<li><p>First, we solve $a_{11} x_1 = b_1$ with $x_1 = b_1 / a_{11}$.</p>
</li>
<li><p>Next we solve $a_{21}x_1 + a_{22}x_2 = b_2$ by first subsititution in for our just-solved $x_1$, and then solving:</p>
</li>
</ul>$$~
a_{21}x_1 + a_{22}x_2 = b_2
~$$
$$~
a_{21} ( b_1 / a_{11})+ a_{22}x_2 = b_2
~$$
$$~
x_2 = (b_2 - a_{21}(b_1/a_{11})) / a_{22}
~$$
<ul>
<li><p>repeat. In general we have</p>
</li>
</ul>$$~
x_i = (b_i - \sum_{j=1}^{i-1} a_{ij} x_j) \cdot \frac{1}{a_{ii}}
~$$
<p>It is important that we have $a_{ii} \neq 0$, as otherwise we will have issues dividing. But this will be the case if $det(A) \neq 0$. (Why?)</p><p>This method is called <em>forward substitution</em></p><h3>Upper triangular matrices</h3><p>A matrix $U$ is <em>upper triangular</em> if $u_{ij} = 0$ if $i < j$. For example:</p>$$~
A = \left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1, n-1} & a_{1n}\\
0 & a_{22} & \cdots & a_{2,n-1} &a_{2n}\\
&&\vdots&&\\
0 & 0 &\cdots & a_{n-1,n-1} & a_{n-1,n}\\
0 & 0 &\cdots & 0 & a_{nn}\\
\end{array}
\right)
~$$
<p>Then solving $Ax=b$ can be done by working <em>backwards</em>:</p>$$~
x_n = b_n / a_{nn}
~$$
<p>and from here:</p>$$~
x_{n-1} = (b_{n-1} - a_{n-1, n}x_n)/a_{n-1, n-1} = (b_{n-1} - a_{n-1, n}) \cdot b_n / a_{nn}/a_{n-1, n-1}
~$$
<p>And in general</p>$$~
x_i = (b_i - \sum_{j=i+1}^n a_{ij} x_j) / a_{ii}.
~$$
<p>Again, we need $a_{ii} = 0$.</p><h2>Permuted L or U matrices</h2><p>Consider</p>$$~
A = \begin{array}{ccc}
1 & 2 & 3\\
0 & 0 & 4\\
0 & 5 & 6
\end{array}
~$$
<p>Clearly if we permuted rows 2 and 3 this would be upper triangular, so we could solve easily by: first solving row 2, then use that to solve row 3 and then finally row 1.</p><p>Define $p = [p_1, p_2, \cdots, p_n]$,  to be a permutation vector if the mapping $i \rightarrow p_i$ maps the set $1, \dots, n$ to itself in a bijective manner <em>and</em> the matrix $(\alpha_{ij}) = (a_{p_i j})$ is either upper or lower triangular.</p><p>(In the above we would have $p_1 = 1, p_2 = 3$, and $p_3 = 2$.)</p><p>Then clearly we could solve the permuted system of equations. For example, in the case that we end up lower triangular, so that forward substitution works, we would have:</p>$$~
x_i = (b_{p_i} -  \sum_{j=1}^{i-1} a_{p_i j}) / a_{p_i i}.
~$$
<h2>Why bother?</h2><p>Suppose we knew that $A=LU$, then we can solve $Ax = b$ easily by:</p><ul>
<li><p>solve the  equatulation $Ly = b$ for $y$.</p>
</li>
<li><p>But $y = Ux$, so we solve $Ux = y$ for $x$.</p>
</li>
</ul><p>So if we can <em>factorize</em> $A = LU$, we can easily solve $Ax = b$.</p><h3>Example</h3><p>In Julia (and MATLAB) there is a built in solver for these problems:</p><pre class="sourceCode julia">U = [1 2; 0 1]</pre>
<pre class="output">
2×2 Array{Int64,2}:
 1  2
 0  1</pre>

<pre class="sourceCode julia">b = [1, 3]
x = U \ b</pre>
<pre class="output">
2-element Array{Float64,1}:
 -5.0
  3.0</pre>

<pre class="sourceCode julia">U*x - b</pre>
<pre class="output">
2-element Array{Float64,1}:
 0.0
 0.0</pre>

<p>In fact, there are many different methods depending on assumptions. For example, rationals:</p><pre class="sourceCode julia">U = [1//1 2; 0 1]
U \ b</pre>
<pre class="output">
2-element Array{Rational{Int64},1}:
 -5//1
  3//1</pre>

<p>There are special methods for many others...</p><h2>Can we find LU for a given A?</h2><p>Suppose $A = LU$, then we have:</p>$$~
a_{ij} = l_{i1} u_{1j} + l_{i2} u_{2j} + \cdots l_{in} u_{nj}
~$$
<p>But:</p><ul>
<li><p>lower triangular means $l_{ij} = 0$ if $j > i$</p>
</li>
<li><p>upper triangular means $u_{ij} = 0$ is $j < i$.</p>
</li>
</ul><p>So</p>$$~
a_{ij} = \sum_{s = 1}^{min(i, j)} l_{is} u_{sj}.
~$$
<p>Now to prove we can find $LU = A$. We will do so by  induction. Suppose we know the first $k-1$ columns of $L$ and the first $k-1$ rows of $U$. We then have:</p>$$~
a_{kk} = \sum_{s=1}^{min(k,k)} \cdot = \sum_{s=1}^k \cdot = \sum_{s=1}^{k-1} l_{ks}u_{sk} + l_{kk} u_{kk}.
~$$
<p>The first part of the right hand sum involves columns of $L$ for which $s < k$ and rows of $U$ or which $s < k$. So all values are known by our assumption. So if $l_{kk}$ is known (say assumed to 1 or some other non-zero value) we can solve for $u_{kk}$ in terms of known values. To be explicit:</p>$$~
u_{kk} = (a_{kk} - \sum_{s=1}^{k-1} l_{ks}u_{sk} ) / l_{kk}.
~$$
<p>Then to fill out the $k$ row of $U$, we consider for $j > k$ (for which $min(j,k) = l$):</p>$$~
a_{kj} = \sum_{s=1}^{k-1} l_{ks} u_{sj} + l_{kk} u_{kj}
~$$
<p>The sum is of known values and $l_{kk}$ is known, so for each $j$, as specified, we can solve for $u_{kj}$.</p><p>Similarly, for the $k$ column of $L$, we consider for $j > k$</p>$$~
a_{jk} = \sum_{s=1}^{k-1} l_{js} u_{sk} + l_{jk} u_{kk}
~$$
<p>As before, the sum is known, and here, so is $u_{kk}$, so we can solve for $l_{jk}$ when $j > k$. That is we can fill in the $k$ column.</p><h3>Special cases</h3><ul>
<li><p>If we always were to take $l_{ii} = 1$ we get Dolittle's factorization</p>
</li>
<li><p>If we always were to take $u_{ii} = 1$ we get Crout's factorization</p>
</li>
<li><p>If we take $u_{ii} = l_{ii}$ we get Cholesky's factorization.</p>
</li>
</ul><h3>Example</h3><p>Let's look at this matrix</p><pre class="sourceCode julia">A = [1 1 1; 1 2 2; 1 2 3]</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  1  1
 1  2  2
 1  2  3</pre>

<p>We need to fill in $U$ and $L$. We start with a zeros:</p><pre class="sourceCode julia">L = zero(A)
U = zero(A)</pre>
<pre class="output">
3×3 Array{Int64,2}:
 0  0  0
 0  0  0
 0  0  0</pre>

<p>Now we fill in: we have $1 = a_{11} = l_{11} u_{11}$ so we can take each to be 1:</p><pre class="sourceCode julia">L[1,1] = 1
U[1,1] = 1</pre>
<pre class="output">
1</pre>

<p>Then for $U$ we need to fill in $u_{12}$ and $u_{23}$. For these we have</p>$$~
a_{12} = 1 = (0) +  l_{11} u_{12} = 1 u_{12}, \quad
a_{13} = 1 = (0) + l_{11} u_{13} = 1 u_{13}
~$$
<p>So both are 1:</p><pre class="sourceCode julia">U[1,2] = 1
U[1,3] = 1</pre>
<pre class="output">
1</pre>

<p>And for the first row of $L$ we have:</p>$$~
a_{21} = 1 = (0) + l_{21}u_{11} = l_{21}, \quad
a_{31} = 1 = (0) + l_{31}u_{11} = l_{31}
~$$
<p>So ditto:</p><pre class="sourceCode julia">L[2,1] = 1
L[3,1] = 1</pre>
<pre class="output">
1</pre>

<p>Moving on to $k=2$ gives first the diagonal terms:</p>$$~
a_{22} = (l_{21} u_{12}) + l_{22} u_{22}, \quad\text{or}
2 = (1 \cdot 1) + l_{22} u_{22}
~$$
<p>We can take both to be $1$:</p><pre class="sourceCode julia">L[2,2] = 1
U[2,2] = 1</pre>
<pre class="output">
1</pre>

<p>And to fill in for $j > 2$:</p>$$~
a_{23} = 2 = (l_{21} u_{13}) + l_{22}u_{23} = (1\cdot 1) + 1 u_{23},
~$$
<p>So $u_{23} = 1$</p><pre class="sourceCode julia">U[2,3] = 1</pre>
<pre class="output">
1</pre>

<p>And from</p>$$~
a_{32} = 2 = (l_{31} u_{12}) + l_{32} u_{22} = (1 \cdot 1) + l_{32} \cdot 1
~$$
<p>So $l_{32} = 1$:</p><pre class="sourceCode julia">L[3,2] = 1</pre>
<pre class="output">
1</pre>

<p>Finally, we need to find the last diagonal terms:</p>$$~
a_{33} = 3 = (l_{31}u_{13} + l_{32}u_{23}) + l_{33} u_{33} = (1\cdot 1 + 1\cdot 1) +  l_{33} u_{33}
~$$
<p>So we can take each to be $1$:</p><pre class="sourceCode julia">L[3,3] = 1
U[3,3] = 1</pre>
<pre class="output">
1</pre>

<pre class="sourceCode julia">L</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  0  0
 1  1  0
 1  1  1</pre>

<p>and</p><pre class="sourceCode julia">U</pre>
<pre class="output">
3×3 Array{Int64,2}:
 1  1  1
 0  1  1
 0  0  1</pre>

<p>And we verify:</p><pre class="sourceCode julia">A - L*U</pre>
<pre class="output">
3×3 Array{Int64,2}:
 0  0  0
 0  0  0
 0  0  0</pre>

<h3>Optimized versions</h3><p>There are built in functions for these:</p><pre class="sourceCode julia">L, U, p =  lu(A)</pre>
<pre class="output">
([1.0 0.0 0.0; 1.0 1.0 0.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 0.0 1.0 1.0; 0.0 0.0 1.0], [1, 2, 3])</pre>

<p>We already verified that $LU = A$ for this $A$. The <code>p</code> is a permulation vector. In general, we should verify</p><pre class="sourceCode julia">A[p,:]  -  L * U</pre>
<pre class="output">
3×3 Array{Float64,2}:
 0.0  0.0  0.0
 0.0  0.0  0.0
 0.0  0.0  0.0</pre>

<h2>When do we know this will work?</h2><p>Define the $k$th leading principal minor of $A$ to be the submatrix $a_{ij}$ for $1 \leq i,j \leq k$. Call this $A_k$.</p><blockquote>
<p>Thm: If $A$ is $n \times n$ and all $n$ leading principle minors are non-singular, then $A$ has an LU decomposition</p>
</blockquote><p>Proof. Suppose by induction this is true for step $k-1$. The we have $A_{k-1}$ can be factored: $A_{k-1} = L_{k-1} U_{k-1}$.</p><p>We wish to find $L_k$ and $U_k$ which are extensions and satisfy $A_k = L_k U_k$.</p><p>Consider the case $1 \leq i \leq k-1$ and</p>$$~
a_{ik} = \sum_{s = 1}^{k-1} l_{is}u_{sk}
~$$
<p>We know the $a_{ik}$, the $l$'s involved are from $L_{k-1}$. The $u$'s we don't know (yet), but as $L_{k-1}$ is non-singular we can solve for the $u$s and this is just of the form $b = L_{k-1} x$. So we can fill out the value of $U_k$.</p><p>Similarly, for $1 \leq j \leq k-1$ we have:</p>$$~
a_{kj} = \sum_{s=1}^{k-1} l_{ks} u_{sj}
~$$
<p>This is of the form $b = U_{k-1} x$ so can be solved to fill out the value of $L_k$.</p><p>FInally, we need to solve for $l_{kk}$ and $u_{kk}$, but we have:</p>$$~
a_{kk} = \sum_s^{k-1} l_{ks} u_{sk} + l_{kk}u_{kk}
~$$
<p>If the value of $l_{kk} = 1$, then $u_{kk}$ can be solved as the sum is now known. That is, we can fill out $L_k$ and $U_k$ with $A_k = L_k U_k$, as desired.</p><h2>Cholesky factorization</h2><p>We know the transpose of a lower triangular matrix is upper and vice versa. This gives hope to a factorization of the form $A = L L^T$, known as the Cholesky factorization. When is this possible?</p><blockquote>
<p>Thm: If $A$ is real, symmetric and positive definite then it has a unque factorization $A=LL^T$ and $L$ has a positive diagonal.</p>
</blockquote><p>Pf: We must have $Ax=0$ has only a solution $x=0$, as positive definite means $x^T A x > 0$ for non-zero $x$. By considering vectors of the form $x = [x_1 x_2 \cdot x_k 0 0 \cdots 0]$ we can see that $A_k$ will also be non-singular.</p><p>So by the last theorem $A= LU$ for some $L$ and $U$. But $A^T = A$ so $LU = (LU)^T = U^T L^T$. Multiplying on the right and left as follows gives</p>$$~
\begin{align}
L^{-1} (L U) (L^T)^{-1} &=L^{-1} U^T L^T (L^T)^{-1}\\
U (L^T)^{-1} &= L^{-1} U^T.
\end{align}
~$$
<p>The left side is upper triangular, the right side lower triangular, hence the must be a diagonal matrix $D$: $D = U (L^T)^{-1}$ and so  $L D = (LU)(L^T)^{-1} = A(L^T)^{-1}$, giving $A = L D L^T$.</p><p>If we can show that $D$ has all positive diagonal terms, then we can define $D^{1/2}$ by $(\sqrt{d_{ii}})$ and express $A$ as $(LD^{1/2}) (LD^{1/2})^T$ which is what we want.</p><p>So, why do we know $D$ has all positive diagonal terms? Because $D$ is positive definite:</p><p>Take $x$ and then:</p>$$~
\begin{align}
x^T D x &= x^T (L^{-1}) A (L^T)^{-1} x\\
&= (x^T L^{-1}) A ((L^T)^{-1} x)\\
&= ((L^{-1})^Tx)^T A ((L^T)^{-1}x)\\
&= ((L^{-1})^Tx)^T A ((L^{-1})^{t}x)
&> 0.
\end{align}
~$$
<p>The last line as $A$ is positive definite and $(L^{-1})^Tx$ is non-zero. The fact we can swap out the inverse and transpose of a matrix is something to prove.</p><h3>Proof take 2</h3><p>Here is an alternative <a href="http://www.math.iit.edu/~fass/477577_Chapter_7.pdf">proof</a>, perhaps more instructive. It requires a few facts about matrices which are symmetric and positive definite:</p><ul>
<li><p>If $A$ is then $a_{11} > 0$.</p>
</li>
<li><p>If $A$ is then any sub matrix formed by removing row $i$ and column $i$ will be</p>
</li>
<li><p>If $A$ is and $L$ has full rank, then $LAL^T$ is one.</p>
</li>
</ul><p>Suppose we have $A$ as assumed. Then we can write $A$ in the following way where $a_{11} > 0$.</p>$$~
A = \left[
\begin{array}{cc}
a_{11} & w^T\\
w & K
\end{array}
\right]
~$$
<p>By the second fact above, $K$ Is symmetric and positive definite.</p><p>Now consider the following lower triangular matrix:</p>$$~
L_1 = \left[
\begin{array}{cc}
\sqrt{a_{11}} & 0\\
\frac{w}{\sqrt{a_{11}}} & I
\end{array}
\right]
~$$
<p>Then using block matrix multiplication we get this decomposition: $A = L B L^T$ where</p>$$~
B_1= \left[
\begin{array}{cc}
I & 0^T\\
0 & K - \frac{ww^T}{a_{11}}
\end{array}
\right].
~$$
<hr /><p>To see:</p><pre class="sourceCode julia">using SymPy
w, K= symbols("w,  K", real=true)
w = [w]	 # a vector
a_11 = symbols("a_11", positive=true)
A = [a_11 w'; w K]
L = [sqrt(a_11) 0; w*(1/sqrt(a_11)) 1]
B_1 = [1 0;0 (K-w*w'*(1/a_11))]

L*B_1*L'</pre>
<div class="well well-sm">
\begin{bmatrix}a_{11}&w\\w&K\end{bmatrix}</div>

<hr /><p>Let $A_1 =  K - ww^T / a_{11}$. Since $A$ is positive definite and $L$ has full rank (why?) it must be $B_1$ is positive definite. Hence, $A_1$ is too. But both $K$ and $ww^T$ are symmetric, so $A_1$ is also symmetric and positive definite.</p><p>So we can find $M_2$, $B_2$, such that $A_1 = M_2 B_2 M_2^T$ and $B_2$ will have a symmetric, positive definite submatrix $A_2$. As written $M_2$ is $n-1 \times n-1$. We embed this into</p>$$~
L_2 =  \left[
\begin{array}{cc}
I & 0^T\\
0 & M_2
\end{array}
\right].
~$$
<p>And then $A = L_1 L_2 A_2 L_2^T L_1^T$ where</p>$$~
A_2 = \left[
\begin{array}{cc}
I_2 & 0^T\\
0   & K_2
\end{array}
\right].
~$$
<p>We see were this repeated, we would eventually get:</p>$$~
A = L_1 L_2 \cdots L_n \cdot I \cdot  L_n^T \cdots L_2^T L_1^T.
~$$
<p>Letting $L = L_1 L_2 \cdots L_n$ yields the result, $A=LL^T$, after noting the the product of lower triangular matrices is lower triangular.</p><h2>Example</h2><p>This comes from statistics. Consider the <em>overdetermined</em> system:</p><pre class="sourceCode julia">A = [1 2; 3 5; 4 7; 1 8]</pre>
<pre class="output">
4×2 Array{Int64,2}:
 1  2
 3  5
 4  7
 1  8</pre>

<pre class="sourceCode julia">b = [1,2,3,4]</pre>
<pre class="output">
4-element Array{Int64,1}:
 1
 2
 3
 4</pre>

<p>The system $Ax=b$ has no solutions. However, this system will:</p>$$~
(A^T A) x = A^T b
~$$
<p>(Assuming $A^TA$ is non-singular, we have it is symmetric and positive definite.)</p><pre class="sourceCode julia">M = A' *A</pre>
<pre class="output">
2×2 Array{Int64,2}:
 27   53
 53  142</pre>

<p>So we can take the cholesky decomposition:</p><pre class="sourceCode julia">U = chol(M)'   # default answer is upper triangular
L = U'</pre>
<pre class="output">
2×2 UpperTriangular{Float64,Array{Float64,2}}:
 5.19615  10.1999 
  ⋅        6.16141</pre>

<p>So we can solve $LL^Tx = A^T b$. First we solve for $y$ in $Ly=A^Tb$ with:</p><pre class="sourceCode julia">y = L \ (A'*b)</pre>
<pre class="output">
2-element Array{Float64,1}:
 -16.282 
  10.5495</pre>

<p>And then solve $L^Tx = y$:</p><pre class="sourceCode julia">x = L' \ y</pre>
<pre class="output">
2-element Array{Float64,1}:
 -3.13347
  6.89947</pre>

<p>This answer is not the "answer" (as that doesn't exist):</p><pre class="sourceCode julia">A*x - b</pre>
<pre class="output">
4-element Array{Float64,1}:
  9.66548
 23.097  
 32.7624 
 48.0623 </pre>

<p>However, it has a property: it is the <code>x</code> with the smallest difference:</p><pre class="sourceCode julia">norm(A*x - b)</pre>
<pre class="output">
63.3265770219158</pre>

<pre class="sourceCode julia">sort([norm(A*rand(2) - b) for _ in 1:10])</pre>
<pre class="output">
10-element Array{Float64,1}:
 1.59631
 2.34953
 2.83948
 2.9917 
 3.05481
 4.25942
 4.66051
 4.73319
 5.00539
 6.7586 </pre>

<h3>Why?</h3><p>(P279) Suppose $Ax=b$ has $A$ being $m \times n$ with $m > n$ and $rank(A) = n$. Then, this will typically have no solutions. In that case, what is sought is a best solution in the sense of minimizing $\| b - Ax \|_2$.</p><p>Now suppose $x$ solves $A^TAx=A^Tb$, and $y$ is some other value, then</p>$$~
\begin{align}
\|b - Ay\|_2^2 &= \|b - Ax + A(x-y)\|_2^2\\
&= (b - Ax + A(x-y))^T \cdot  (b - Ax + A(x-y))\\
&= (b - Ax)^T\cdot (b-Ax) + (b-Ax)^T\cdot (A(x-y)) + (A(x-y))^T \cdot (b-Ax) + (A(x-y)^T) \cdot (A(x-y))\\
&= \| b - Ax \|_2^2 + 0 + 0 + \|A(x-y)\|_2^2\\
&\geq  \| b - Ax \|_2^2
\end{align}
~$$
<p>The latter because, $Ax-b$ has a $0$ dot product with vectors in the column space of $A$ (as $A^T(Ax-b)=0$. But $A(x-y)$ is in the column space of $A$. (Any $Az = [A_{\cdot 1} ; A_{\cdot 2} ; \cdots ; A_{\cdot n}] \cdot z = z_1A_{\cdot 1} + z_2A_{\cdot 2} + \cdots + z_n A_{\cdot n}$.) So, the cross terms are 0 and the result holds.</p>
  </div>
</div>  

</body>
</html>
