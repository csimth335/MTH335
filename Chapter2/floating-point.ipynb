
{
  "cells": [
     {"cell_type":"markdown","source":"<h1>Floating point numbers</h1>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<h2>Decimal numbers</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>In mathematics we have different types of numbers: Integers, Rationals, Reals, ...</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>On a calculator there is one: floating point</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>On the computer there may be more than one type for each mathematical type: 8, 16, 32, 64, 128 bit integers...</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>In mathematics we primarily work with <em>decimal numbers</em></p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ 12.34 = 1 \\cdot 10^2 + 2 \\cdot 10^1 + 3\\cdot 10^{-1} + 4 \\cdot 10^{-2} $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Rounding</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>We are familiar with the task of rounding: a passing grade is 59.5 not a 60!</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>We have three types of rounding: round up, round down, mixing based on a rule.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Rounding to the nearest integer shows this fairly clearly:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4.0,3.0,3.0)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["x = 3.14\nceil(x), floor(x), round(x)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>The same would be true of $3.1$, as that is all that is looked at here.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>What becomes of $1.5$? The default is to round up.</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2.0,1.0,2.0)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["x = 1.5\nceil(x), floor(x), round(x)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Rounding can be done for real numbers too to some specified number of digits:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.2,1.23,1.2346)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["x = 1.23456\nround(x,1), round(x,2), round(x,4)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Error bound</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Let $x$ be the number and $\\tilde{x}$ be its rounded value. How big is the difference when $x$ is rounded to $n$ decimal places?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>We consider the value of the $n+1$st decimal number.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>- If it is in 0,1,2,3,4 then we round down and the error is $i \\cdot 10^{-(n+1)}$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>- If it is in 5,6,7,8,9 then we round up, and the error is $10-i \\cdot 10^{-(n+1)}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>In either case, it is less –in absolute value – than $5*10^{-(n+1)} = 1/2 \\cdot 10^{-n}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<blockquote><p>The error in rounding to $n$ decimal points is bounded by: $|x - \\tilde{x}| < 1/2 \\cdot 10^{-n}$. </p></blockquote>","metadata":{}},
{"cell_type":"markdown","source":"<p>Had we chopped (<code>floor</code>) or always rounded up (<code>ceil</code>) then the error is bounded by $10^{-n}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Scientific notation</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>We can write a real number in terms of powers of 10. For example:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ 1.234 = 1.234 \\cdot 10^0 =  12.34 \\cdot 10^{-1} =  .1234 \\cdot 10^1 = \\cdots $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>We can use normalized scientific notation to say that we can express $x$ by three quantities:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ x = \\pm r \\cdot 10^n $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>$\\pm$ is $+1$ or $-1$ records the sign of $x$</li><li>$r$ is a number in $0.1 \\leq r < 1.0$</li><li>$n$ is an integer, possible negative, or zero.</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>A more useful representation for storing on the computer is to shift things over by $1$ to get</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>$r$ is a number in $1 \\leq r < 10$</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Binary numbers</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Binary numbers are similar, only we use base $2$ – not $10$, as with decimal.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>So</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ (10.101)_2 = 1 \\cdot 2^1 + 0 \\cdot 2^0 + 1 \\cdot 2^{-1} + 0 \\cdot 2^{-2} + 1 \\cdot 2^{-3} $$</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.625"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["1*2^1 + 0*2^0 + 1*1/2^1 + 0 * 1/2^2 + 1 * 1/2^3"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Scientific notation with base 2</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>We can use different bases in scientific notation. Any number can be written as</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ x = \\pm q \\cdot 2^m $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>With</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>$\\pm$ represents $+1$ or $-1$</li><li>$q$ -- the significand -- has $1 \\leq q < 2$ (in base 2)</li><li>$m$ -- is an integer (in base 2)</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>By writing $q = 1.f$ an extra digit can be gained (the 1) if only a finite number of digits are available, as is the case on the computer.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>(In general, with a base $\\beta$, we can write $x=\\pm q \\cdot \\beta^m$ where $q$ is written in base $\\beta$.)</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Floating point numbers</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Floating point is a representation of numbers using scientific notation, as above, except there are only finitely many digits that can be used for $q$ and $m$. For example, we might restrict $q$ to hold just $p$ digits ($p$ is the <em>precision</em>), and $m$ will have another restriction on the size of its digits.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>For example, let's consider numbers of the type $d.dd \\cdot 10^m$ – that is $p=3$ where $m$ is in $\\{-1,0,1,2\\}$. Then some numbers are: <code>1.23e3</code> , <code>-1.2oe-1</code>, <code>1.99e0</code>, ... In each case, $q$ has 3 digits and is in $[1,10)$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>## Binary floating point</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>For binary floating point, things are similar. For <em>simplicity</em> let's look at 16-bit floating point where</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>- 1 bit is the sign bit <code>0</code> = $+1$, <code>1</code> is $-1$ - $q$ is represented with $10$ bits (the <em>precision</em> is 10) - $m$ is represented with $5$ bits.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>There is nothing to represent the <em>sign</em> of $m$. The trick is offset the value by subtracting and using  $m -15.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>With this, can we represent some numbers:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>What is $1$? It is $+1 \\cdot 1.0 \\cdot 10^{15 - 15}$. So we should have</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>- sign is <code>0</code> - $q$ is <code>0000000000</code> - $m$ is <code>01111</code></p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Checking we have</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"0011110000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["convert(Float16, 1.0) |> bits"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Kinda hard to see: Let's wrap this in a function:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["seebits (generic function with 1 method)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["function seebits(x)\n  b = bits(convert(Float16,x))\n  b[1], b[2:6], b[7:end]\nend"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"01111\",\"0000000000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(1)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>We have $2 = 1.0 \\cdot 2^1$. Se we expect $q$ to represent $0$ and $m$ to represent $16$, as $16-15 = 1$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"10000\",\"0000000000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(2)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>What about the sign bit?</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('1',\"10000\",\"0000000000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(-2)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>What about other numbers</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"01111\",\"1110100000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(1 + 1/2 + 1/4 + 1/8 + 0/16 + 1/32)"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"10011\",\"1110100000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(2^4*(1 + 1/2 + 1/4 + 1/8 + 0/16 + 1/32)) ## 19 - (1 + 1*2 + 1*16) = 0"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Numbers get rounded!</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["float16(0.099976)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["convert(Float16, 0.1)"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"01011\",\"1001100110\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["seebits(0.1)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>\"1001100110\" becomes:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.599609375"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["q = (1 + 1/2 + 1/16 + 1/32 + 1/256 + 1/512 )"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>And <code>01011</code> for $m$ becomes</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0625"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["m = 2.0^(1 + 2 + 8 - 15)"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.6704301324376012"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["1 * q * 2^m"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Notice the number $0.1$ is necessarily approximated.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Float16, Float32, Float64, ...</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>16-bit floating point is not typical. What is common is:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>64-bit floating point (in Julia `Float64`)</li><li>32-bit floating point (older hardward and OSes)</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>How the bits are arranged in IEEE 754 binary formats for <a href=\"http://tinyurl.com/76kpk6s\">floating point</a> we have this <a href=\"http://tinyurl.com/76kpk6s\">table</a>. See also this post by John <a href=\"http://www.johndcook.com/blog/2009/04/06/anatomy-of-a-floating-point-number/\">Cook</a> for the common case.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>For example</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0',\"10000000001\",\"0110100000000000000000000000000000000000000000000000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["b = bits(2^2 + 2^0 + 1/2 + 1/8) ## 101.101 = 1.01101 * 2^2\nb[1], b[2:12], b[13:end]"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Here $m = 2^10 + 1 - (2^10 - 1)$ and we can see that $q=1.01101$ with the first $1$ implicit.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>## 0, Infinity, NaN</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Some values in floating point are special:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>$0$: how to write $0$ in $1.f \\cdot 2^m$? Can't do it. So it is coded:</li></ul>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"0000000000000000000000000000000000000000000000000000000000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(0.0)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<ul><li>$-0$: By flipping the sign bit, we could code $-0$ naturally. Is it done?</li></ul>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"1000000000000000000000000000000000000000000000000000000000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(-0.0)   ## why??"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<ul><li>Infinity. [Why](http://www.cs.berkeley.edu/~wkahan/Infinity.pdf)?</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>This value is deemed valuable to have supported at the hardware level. It is coded by reserviing the largest value of $m$:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"0111111111110000000000000000000000000000000000000000000000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(Inf)  # see bits(Inf)[2:12]"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>There is room for $-\\infty$ and it too is defined:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"1111111111110000000000000000000000000000000000000000000000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(-Inf)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<ul><li>NaN. This is a special value reserved for computations where no value is possible. Examples include `0/0` or `0 * Inf`:</li></ul>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(NaN,NaN)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["0/0, 0 * Inf"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>These are related to limit problems (indeterminate), though not all forms are indeterminate:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Inf,1)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["1/0, 0^0"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>How is <code>NaN</code> coded:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"0111111111111000000000000000000000000000000000000000000000000000\""]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(NaN)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>This is <em>very</em> similar to <code>Inf</code>, but the value of $q$ is non-zero!</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(\"1000000000000000000000000000000000000000000000000000\",\"0000000000000000000000000000000000000000000000000000\")"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["bits(NaN)[13:end], bits(Inf)[13:end]"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Range of numbers</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>What is the range of the numbers that can be represented? Let's check with Float16.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The largest <em>positive</em> value would have $m$ coded with <code>11110</code> or ($2 + 4 + 8 + 16 - 15 = 15$)</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The largest value for $q$ would be <code>1111111111</code>, or</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.9990234375"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sum([1/2^i for i in 0:10])"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Altogether we have:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["65504.0"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sum([1/2^i for i in 0:10]) * 2^15"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Is this right?</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["float16(65504.0)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["prevfloat(typemax(Float16))"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>For the smallest <em>positive</em> number, the smallest exponent is code <code>00000</code> or $0 - 15 = -15$. So the value should be:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["-6.1005353927612305e-5"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["-sum([1/2^i for i in 0:10]) * 1/2^15"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>But this isn't actually the case:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["float16(5.9605e-8)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["nextfloat(convert(Float16, 0))"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>(As there are tricks to get smaller numbers called subnormal numbers)</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>For double precision numbers (Float64) the values are given by:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.7976931348623157e308,5.0e-324)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["prevfloat(Inf), nextfloat(0.0)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h2>Machine numbers</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>The numbers that can be represented <strong>exactly</strong> in floating point are called <em>machine number</em>.</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>There aren't very many compared to the **infinite** number of floating point values.</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>Let's visualize in a <em>hypothetical</em> Float8 mode with 1 sign bit, 3 exponent bits and 4 bits for the mantissa.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The possible <em>positive</em> values are</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["16-element Array{Float64,1}:\n 1.0   \n 1.0625\n 1.125 \n 1.1875\n 1.25  \n 1.3125\n 1.375 \n 1.4375\n 1.5   \n 1.5625\n 1.625 \n 1.6875\n 1.75  \n 1.8125\n 1.875 \n 1.9375"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["qs = [1 + i/2 + j/4 + k/8 + l/16 for i in 0:1, j in 0:1, k in 0:1, l in 0:1] |> vec |> sort"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>The values for the exponents are $-3, -2, -1, 0, 1, 2, 3$. So all our values are given by</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["112-element Array{Any,1}:\n  0.125   \n  0.132813\n  0.140625\n  0.148438\n  0.15625 \n  0.164063\n  0.171875\n  0.179688\n  0.1875  \n  0.195313\n  0.203125\n  0.210938\n  0.21875 \n  ⋮       \n 10.0     \n 10.5     \n 11.0     \n 11.5     \n 12.0     \n 12.5     \n 13.0     \n 13.5     \n 14.0     \n 14.5     \n 15.0     \n 15.5     "]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["ms = (-3):3\nvals = [q * 2.0^m for q in qs, m in ms] |> vec"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Plotting the machine numbers</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>We can plot these points:</p>","metadata":{}},
{"outputs":[{"data":{"text/plain":["Plot(...)"],"image/png":"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"}}],"cell_type":"code","source":["using Gadfly\nplot(x = vals, y = 0*vals, Geom.point)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>We notice:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>they are definitely finite</li><li>there are definitely gaps</li><li>they are not evenly spaced out</li><li>there is a \"hole\" near 0</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Machine precision</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Of special note is the size of the gap between values around 1:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0000000000000002"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["nextfloat(1.0)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>This is sometimes called <em>machine precision</em> and in <code>Julia</code> is returned by <code>eps()</code>:</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.220446049250313e-16"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["eps()"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["float16(0.00097656)"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["eps(Float16)"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h3>Rounding</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>As not every number is a machine number, numbers are rounded to machine numbers. There are variants of rounding methods. Some are:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>round to nearest: find the closest machine number. If a tie round to the even number.</li><li>round to $0$: round down if positive, up if negative</li><li>round to $\\infty$ (or $-\\infty$): always round up (or down)</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>How big can the error be in rounding one number? Let $p$ be the precision and $\\beta=2$, for simplicity we take $p=3$. We can write</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ x=1.a_1 a_2 a_3 a_4 \\dots 2^m = 1.a_1 a_2 a_3 2^m + e $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>where</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ e=.000a_4 a_5 \\dots 2^m = 0.a_4a_5\\dots 2^{-p} 2^m. $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>If we round down, we take $e=0$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>If we round up, we take $e = 1\\cdot 2^{-p} 2^m$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>At most the error is $1/2 2^{-p} 2^m$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The <em>relative error</em> is at most</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ |\\frac{x - fl(x)}{x}| = |\\frac{e}{x} = \\frac{1/2 2^{-p} 2^m}{q 2^m} \\leq 1/2 2^{-p} $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>(With just chopping there would be no $1/2$.)</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The book writes $fl(x)$ for the floating point value of $x$. If $\\delta$ is the relative error, then we have $fl(x) = x (1 + \\delta)$ and $|\\delta| \\leq 1/2 2^{-p}$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>next closest number</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Suppose $x = 1.a_1a_2 \\cdot a_p \\cdot 2^m$ is a machine number with precision $p$. What is the relative size of the next largest number? This would be</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ x' = (1.a_1a_2 \\cdot a_p + 2^{-p}) \\cdot  2^m $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The absolute difference being $2^{m-p}$. So if $m$ is larger, the difference is larger – bigger gaps. The <em>relative difference</em> is basically a constant: $2^{-p}2^m/(q 2^m) \\leq 2^{-p}$. </p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Error analysis of arithmetic operations</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Rounding can mess with our \"inituitive\" ideas of how numbers work: Consider the familiar decimal case with $p=3$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>What is $10.1 - 9.93$?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>In regular subtraction we align the decimal points</p>","metadata":{}},
{"outputs":[],"cell_type":"code","source":["Verbatim(\"\"\"\n10.10\n09.93\n-----\n00.17\n\"\"\")"],"metadata":{},"input":"10.10\n09.93\n-----\n00.17\n","execution_count":null},
{"cell_type":"markdown","source":"<p>On the computer though values are shifted to align the decimal points. Hence $9.93$ could become $0.99 \\cdot 10^{1}$, if chopped. So that subtraction becomes</p>","metadata":{}},
{"outputs":[],"cell_type":"code","source":["Verbatim(\"\"\"\n10 *  1.01\n      0.99\n      ----- \n10 *  0.02\n\"\"\")"],"metadata":{},"input":"10 *  1.01\n      0.99\n      ----- \n10 *  0.02\n","execution_count":null},
{"cell_type":"markdown","source":"<p>The difference between $.20$ and $.17$ is 3 units in the off in the last digit of precision. So rounding can have an adverse effect.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>### How far off can subtraction with shifting and truncation be?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Suppose we have  precision $p$ and binary ($\\beta=2$). Then the <em>relative</em> error can be as large as 1 = $\\beta-1$!</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Consider a small case: $1.00 \\cdot 2^0$ and $1.11 \\cdot 2^{-1}$. (These are adjacent). Then mathematically the difference is $0.001$, but if $1.11 2^{-1}$ is shifted (and chopped) to $0.11 \\cdot 2^0$ to match, then the difference is $0.01$. We have $|(0.001 - 0.01)/(0.001)| =  1$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>To work around this loss, <em>guard bits</em> are used in practice.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Analysis of floating point operations</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Consider more generally the basic operations of addition, subtraction, multiplication, and division.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Let's assume (contrary to above) that the operations on floating point are correctly done and <em>then</em> rounded to a machine number. (This can be arranged by using more bits for intermediate computations).</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>If $\\odot$ is any of the above operations, what is $fl(x \\odot y)$?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>We know for $x$ that $fl(x) = x(1 + \\delta)$ where $\\delta$ is small ($\\leq 2^{-p}$) and depends on $x$. So,</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ fl(x \\odot y) = fl(fl(x) \\odot fl(y)) = <a href=\"1 + \\delta\">(x(1+\\delta_x) \\odot (y(1 + \\delta_y))</a> $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Each $\\delta is small.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Well, how much off are we?</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/latex":["$$d_{1} d_{2} d_{3} + d_{1} d_{2} + d_{1} d_{3} + d_{1} + d_{2} d_{3} + d_{2} + d_{3}$$"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["using SymPy\nx,y,d1,d2,d3 = symbols(\"x,y,d1,d2,d3\", real=true)\nop = *\n( op(x*(1+d1), y*(1+d2)) * (1 + d3) - op(x,y))/op(x,y) |> expand"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/latex":["$$\\frac{d_{1} d_{3} y}{d_{2} y + y} + \\frac{d_{1} y}{d_{2} y + y} + \\frac{d_{3} y}{d_{2} y + y} + \\frac{y}{d_{2} y + y} - 1$$"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["op = /\n( op(x*(1+d1), y*(1+d2)) * (1 + d3) - op(x,y))/op(x,y) |> expand"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>But...</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/latex":["$$\\frac{d_{1} d_{3} x}{x - y} + \\frac{d_{1} x}{x - y} - \\frac{d_{2} d_{3} y}{x - y} - \\frac{d_{2} y}{x - y} + \\frac{d_{3} x}{x - y} - \\frac{d_{3} y}{x - y}$$"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["op = -\n( op(x*(1+d1), y*(1+d2)) * (1 + d3) - op(x,y))/op(x,y) |> expand"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<h2>Addition of numbers and cumulative error</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>How do errors accumulate?</p>","metadata":{}},
{"cell_type":"markdown","source":"<blockquote><p>Theorem 1 (p49) relative error in $\\sum_0^n x_i$ is $(1_\\epsilon)^n-1 \\approx n\\epsilon$. </p></blockquote>","metadata":{}},
{"cell_type":"markdown","source":"<p>Let $S_{k+1} = x_{k+1} + S_k$ be the partial sum and $S^<em>_{k+1} = fl(x_{k+1} + S</em>_k) = (x_{k+1}+S^*_k)(1+\\delta_{k+1}$ be the floating point partial sum. What is the relative difference?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ \\frac{S_{k+1} - S^*_{k+1}}{S_{k+1}} = \\frac{S_{k+1}(1+\\delta) - S^*_{k+1}(1+\\delta) - S_{k+1}\\delta}{S_{k+1} = (1 + \\delta)\\frac{S_k - S^*_k}{S_k}\\frac{S_k}{S_{k+1}} - \\delta $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Let $\\rho_k$ be the absolute value. Then $\\rho_{k+1} \\leq \\rho_k(1+\\epsilon) + \\espilon$ with $\\rho_0 = 0$. This can be solved to yield: $\\rho_n \\leq (1 + \\epsilon)^n - $.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Other bounds</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>The maximal possible error for accumulating sums grows <em>linearly</em> with the number of sums. There are other algorithms to cut this down. In Julia, <a href=\"https://en.wikipedia.org/wiki/Pairwise_summation\">pairwise</a> summation is used. This has relative error given by $\\epsilon \\log_2(n)$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>## Loss of significance</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Return to</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/latex":["$$\\frac{d_{1} d_{3} x}{x - y} + \\frac{d_{1} x}{x - y} - \\frac{d_{2} d_{3} y}{x - y} - \\frac{d_{2} y}{x - y} + \\frac{d_{3} x}{x - y} - \\frac{d_{3} y}{x - y}$$"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["op = -\n( op(x*(1+d1), y*(1+d2)) * (1 + d3) - op(x,y))/op(x,y) |> expand"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>The presence of the difference in the denominator can be a problem.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>In the book, we have Thm 1 of section 2.2</p>","metadata":{}},
{"cell_type":"markdown","source":"<blockquote><p>If $x$ and $y$ are binary floating point numbers with $x > y > 0$ with </p></blockquote>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ 2^{-q} \\leq 1 - y/x \\leq 2^{-p} $$ Then at most $q$ and <em>at least</em> $p$ significant binary bits are lost in the substraction $x-y$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The lower bound:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Say $x = r \\cdot 2^n$ and $y=s\\cdot 2^m$ with $m \\leq n$ and here $1/2 \\leq r, s < 1$. Then to \"line up the decimal points\" we may write $y = s \\cdot 2^(m-n) \\cdot 2^n$.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ x - y = (r - s\\cdot 2^{m-n}) \\cdot 2^n $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The significand then satisfies:</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>$$ r - s \\cdot 2^{m-n} = r(1 - \\frac{s\\cdot 2^m}{r \\cdot 2^n}) = r(1 - y/x) < 2^{-p} $$</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>To put into normalized floating point, the significand must be shifted (there are leading $0$s) and the (at least) $p$ terms added are spurious, so accuracy is lost.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h3>Example</h3>","metadata":{"internals":{"slide_type":"subslide"},"slideshow":{"slide_type":"subslide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>Consider $\\sin(x) \\approx x$. So $\\sin(x) - x$ will cause issues.</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["-5.086014673919698e-6"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["x = 1/2^5\nX = big(1/2^5)   # more precision\nsin(x) - x"],"metadata":{},"execution_count":null},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["-5.086014673921260418878742535535373921881201068959602540274778455791996714357325e-06 with 256 bits of precision"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sin(X) - X"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>Only accurate to the 10th digit – not the 16th. There is a loss of accuracy</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>Compare this to</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.062494913985326084"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sin(x) + x"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>and</p>","metadata":{}},
{"outputs":[{"output_type":"execute_result","data":{"text/plain":["-5.086014673921260418878742535535373921881201068959602540274778455791996714357325e-06 with 256 bits of precision"]},"metadata":{},"execution_count":null}],"cell_type":"code","source":["sin(X) - X"],"metadata":{},"execution_count":null},
{"cell_type":"markdown","source":"<p>The moral of the story – try to avoid these.</p>","metadata":{}},
{"cell_type":"markdown","source":"<h2>Accuracy of functions</h2>","metadata":{"internals":{"slide_type":"subslide","slide_helper":"subslide_end"},"slideshow":{"slide_type":"slide"},"slide_helper":"slide_end"}},
{"cell_type":"markdown","source":"<p>In <code>Julia</code> there are many \"redundant\" functions:</p>","metadata":{}},
{"cell_type":"markdown","source":"<ul><li>`sinpi` for computing $\\sin(\\pi x)$, `cospi`, ...</li><li>`expm` to compute $e^x - 1$ for $x$ near 0</li><li>`log1p` to compute $\\log(1+x)$ near 0</li></ul>","metadata":{}},
{"cell_type":"markdown","source":"<p>The reason for <code>expm</code> seems clear. $e^x \\approx 1 + x + x^2/2! + \\cdot$, so $e^x-1$ for small $x$ is a subtraction of like-sized values.</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>For <code>log1p</code> <a href=\"http://www.johndcook.com/blog/2010/06/07/math-library-functions-that-seem-unnecessary/\">Cook</a> if $x$ is really small, say $x=10^{-17}$ (<code>x < eps()</code>), then what happens to $1 + x$? In floating point it is 1. But $\\log(1+x) \\approx x$ by Taylor, so the absolute error is $x$ and the relative error $1$. Quite large. There are more floating point values closer to $0$ than $1$, so smaller values of $x$ can be used in <code>log1p</code>. </p>","metadata":{}},
{"cell_type":"markdown","source":"<p>What about <code>sinpi</code>?</p>","metadata":{}},
{"cell_type":"markdown","source":"<p>The first step in </p>","metadata":{}}
    ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.9",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0

}
