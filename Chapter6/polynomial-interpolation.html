
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1">




<link
  href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
  rel="stylesheet">

<style>
.julia {font-family: "Source Code Pro";
        color:#0033CC;
        }
body { padding-top: 60px; }
h5:before {content:"\2746\ ";}
h6:before {content:"\2742\ ";}
pre {display: block;}
</style>

<script src="http://code.jquery.com/jquery.js"></script>
<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>

<!-- .julia:before {content: "julia> "} -->

<style></style>

<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


<!-- not TeX-AMS-MML_HTMLorMML-->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG">  
</script>
<script>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ["\$","\$"], ["\\(","\\)"]]
  },
  displayAlign: "left",
  displayIndent: "5%"
});
</script>


<script type="text/javascript">
$( document ).ready(function() {
  $("h1").each(function(index) { 
       var title = $( this ).text()
       $("#page_title").html("<strong>" + title + "</strong>");
       document.title = title
  });
  $( "h2" ).each(function( index ) {
    var nm =  $( this ).text();                                    
    var id = $.trim(nm).replace(/ /g,'');
    this.id = id
    $("#page_dropdown").append("<li><a href='#" + id + "'>" + nm + "</a></li>");
  });
  $('[data-toggle="popover"]').popover();  
});
</script>

</head>


<body data-spy="scroll" >

<nav class="navbar navbar-default  navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
         
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="#" id="page_title"></a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
         <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
           Jump to... <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu" id="page_dropdown"></ul>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

<header>
</header>

<div class="container-fluid">
  <div class="span10 offset1">
<h1>Polynomial Interpolation</h1><p>The problem: we know a function's value at some points, $(x_0, y_0)$, $(x_1, y_1), \dots, (x_n, y_n)$. How can we approximate that function?</p><p>There are many functions that can go through a sequence of points, the problem is not unique in general.</p><p>However Theorem 1 on polynomial interpolation (p309)</p><blockquote>
<p>There is a <em>unique</em> polynomial of degree $n$ going through the $n+1$ points. (We assume the $x_i$ are real.)</p>
</blockquote><h2>Uniqueness</h2><p>Well, suppose there are two such polynomials $p(x)$ and $q(x)$. Then we have $h(x) = p(x) - q(x)$. It has degree at most $n$, so there are no more than $n$ roots. But $h(x_i) = p(x_i) - q(x_i) = y_i - y_i = 0$. So there are $n+1$ roots, hence a contradiction.</p><h2>Existence</h2><p>For existence, we can use induction.</p><p>For $n=0$ we just have a constant $p_0(x) = y_1$ and then $p_0(x_1) = y_1$ too.</p><p>For $n=1$: we have two points and we can make the line between them. The point slope form is helpful, it would look like:</p>$$~
p_1(x) = x_0 + \frac{y_1 - y_0}{x_1 - x_0} (x - x_0).
~$$
<hr /><p>Assuming that the statement is true for $k$, can we show it is true for $k+1$.</p><p>First from $p_{k-1}$ with degree $\leq k-1$ from the first $k-1$ points. Then we write the following formally:</p>$$~
p_k = p_{k-1}(x) + c(x-x_0)(x-x_1)\cdots (x - x_{k-1})
~$$
<p>For some $c$ we will show that this polynomial has degree $\leq k$ and $p_k(x_i) =y_i$ for all $i$ between $0$ and $k$.</p><p>The term added is an $k$th degree polynomial. So $p_k$ is a polynomial of degree $\leq k$ and degree of $p_{k-1}$.</p><p>The term added is $0$ at each of $x_0, \dots, x_{k-1}$, so for these values</p>$$~
p_k(x_i) = p_{k-1}(x_i) + 0 = y_i.
~$$
<p>Finally, $p_k(x_n) = p_{k-1}(x_k) + c \prod_{i=0}^{k-1}(x_k - x_i)$</p><p>Setting this to $y_k$ gives:</p>$$~
y_k=  p_{k-1}(x_k) + c \prod_{i=0}^{k-1}(x_k - x_i)
~$$
<p>Or</p>$$~
c = \frac{y_k - p_{k-1}(x_k)}{\prod_{i=0}^{k-1}(x_k - x_i)}.
~$$
<p>The divisor is clearly not $0$, so this defines $c$ and we have found $p_k$.</p><h3>The form of the polynomial</h3><p>We have just seen that</p>$$~
p_k(x) = c_0 + c_1(x-x_0) + c_2(x-x_0)(x-x_1) + \cdots + c_k(x-x_0)\cdots(x-x_{k-1}) =
\sum_{i=0}^{k} c_i \prod_{j=0}^{i-1} (x - x_j).
~$$
<p>where</p>$$~
c_k = \frac{y_k - p_{k-1}(x_k)}{\prod_{i=0}^{k-1}(x_k - x_i)}.
~$$
<h3>The Lagrange form of the polynomial:</h3><p>There are other means to express this polynomial, that are a bit clearer.</p><p>The Lagrange form of the interpolating polynomial uses the $y_i$ as coefficients:</p>$$~
L(x) = \sum y_i \cdot l_i(x),
~$$
<p>Where</p>$$~
l_i(x) = \prod_{m \neq i} \frac{x - x_m}{x_i - x_m}.
~$$
<p>Why this? We want a polynomial that a) takes a value of $0$ at $x_j$ ($j \neq i$) and $1$ at $x_i$. Clearly a) is satisfied by $c(x - x_0) \cdot (x - x_k)$ <strong>skipping</strong> $x_i$. Putting in $x_i$, then says $c$ should be the reciprocal of $(x_i-x_0) \cdots (x_i - x_k)$ <strong>skipping</strong> $x_i-x_i$.</p><p>These are polynomials of degree $n$. using the delta function, these satisfy:</p>$$~
l_i(x_j) = \delta_{ij}.
~$$
<p>So $L(x_i) = \sum_j y_i \delta_{ij} = y_i \cdot 1 = y_i$, as expected. So $L(x)$ is a polyonmial of degree at most $n$ and by uniqueness is the <em>interpolating</em> polynomial.</p><h3>Alternate derivations</h3><p>Suppose we have a polynomial $p_k(x) = a_0 + a_1x + a_2x^2 + \cdots a_k x^k$ which satisfies $p_k(x_i) = y_i$. Then this leads to a system of equations:</p>$$~
\begin{array}{cc}
&a_0 \cdot 1 + a_1 x_0 + a_2 x_0^2 + \cdots + a_k x_0^k = y_0\\
&a_0 \cdot 1 + a_1 x_1 + a_2 x_1^2 + \cdots + a_k x_1^k = y_1\\
&\cdots\\
&a_0 \cdot 1 + a_1 x_k + a_2 x_k^2 + \cdots + a_k x_k^k = y_k
\end{array}
~$$
<p>This is a <em>linear</em> system of $k+1$ equations in $k+1$ unknowns $a_0, a_1, \dots, a_k$. If the coefficient matrix is nonsingular, it has solution $A^{-1}y$.</p><p>For example</p><pre class="sourceCode julia">using SymPy
k=2
xs = Sym["x$i" for i in 0:k]
ys = Sym["y$i" for i in 0:k]
as = Sym["a$i" for i in 0:k]

x = symbols("x")
p = sum([as[i+1] * x^i for i in 0:k])

eqs = Sym[subs(p, x, u) - v for (u,v) in zip(xs, ys)]</pre>
<div class="well well-sm">
\begin{bmatrix}a_{0} + a_{1} x_{0} + a_{2} x_{0}^{2} - y_{0}\\a_{0} + a_{1} x_{1} + a_{2} x_{1}^{2} - y_{1}\\a_{0} + a_{1} x_{2} + a_{2} x_{2}^{2} - y_{2}\end{bmatrix}</div>

<p>We can solve these (they are linear after all):</p><pre class="sourceCode julia">us = solve(eqs, as)</pre>
<div class="well well-sm">
\begin{equation*}\begin{cases}a_{0} & \text{=>} &\frac{x_{0} x_{1} y_{2} \left(x_{0} - x_{1}\right) - x_{0} x_{2} y_{1} \left(x_{0} - x_{2}\right) + x_{1} x_{2} y_{0} \left(x_{1} - x_{2}\right)}{x_{0}^{2} x_{1} - x_{0}^{2} x_{2} - x_{0} x_{1}^{2} + x_{0} x_{2}^{2} + x_{1}^{2} x_{2} - x_{1} x_{2}^{2}}\\a_{2} & \text{=>} &\frac{y_{0} \left(x_{1} - x_{2}\right) - y_{1} \left(x_{0} - x_{2}\right) + y_{2} \left(x_{0} - x_{1}\right)}{x_{0}^{2} x_{1} - x_{0}^{2} x_{2} - x_{0} x_{1}^{2} + x_{0} x_{2}^{2} + x_{1}^{2} x_{2} - x_{1} x_{2}^{2}}\\a_{1} & \text{=>} &\frac{- y_{0} \left(x_{1}^{2} - x_{2}^{2}\right) + y_{1} \left(x_{0}^{2} - x_{2}^{2}\right) - y_{2} \left(x_{0}^{2} - x_{1}^{2}\right)}{x_{0}^{2} x_{1} - x_{0}^{2} x_{2} - x_{0} x_{1}^{2} + x_{0} x_{2}^{2} + x_{1}^{2} x_{2} - x_{1} x_{2}^{2}}\\\end{cases}\end{equation*}</div>

<p>But it isn't pretty and doesn't get prettier with factoring</p><pre class="sourceCode julia">Dict(k=>factor(v) for (k,v) in us)</pre>
<div class="well well-sm">
\begin{equation*}\begin{cases}a_{0} & \text{=>} &\frac{1}{\left(x_{0} - x_{1}\right) \left(x_{0} - x_{2}\right) \left(x_{1} - x_{2}\right)} \left(x_{0}^{2} x_{1} y_{2} - x_{0}^{2} x_{2} y_{1} - x_{0} x_{1}^{2} y_{2} + x_{0} x_{2}^{2} y_{1} + x_{1}^{2} x_{2} y_{0} - x_{1} x_{2}^{2} y_{0}\right)\\a_{2} & \text{=>} &- \frac{x_{0} y_{1} - x_{0} y_{2} - x_{1} y_{0} + x_{1} y_{2} + x_{2} y_{0} - x_{2} y_{1}}{\left(x_{0} - x_{1}\right) \left(x_{0} - x_{2}\right) \left(x_{1} - x_{2}\right)}\\a_{1} & \text{=>} &\frac{x_{0}^{2} y_{1} - x_{0}^{2} y_{2} - x_{1}^{2} y_{0} + x_{1}^{2} y_{2} + x_{2}^{2} y_{0} - x_{2}^{2} y_{1}}{\left(x_{0} - x_{1}\right) \left(x_{0} - x_{2}\right) \left(x_{1} - x_{2}\right)}\\\end{cases}\end{equation*}</div>

<h3>Vandermonde matrix</h3><p>A <a href="https://en.wikipedia.org/wiki/Vandermonde_matrix">Vandermonde</a> matrix is a matrix with a geometric progression in each row. For example, the matrix:</p>$$~
\begin{bmatrix}
1 & x_0 & x_0^2  & \cdots & x_0^k\\
1 & x_1 & x_1^2  & \cdots & x_1^k\\
  &     & \cdots &        & \\
1 & x_k & x_k^2 & \cdots & x_k^k
\end{bmatrix}
~$$
<p>Calling this $V$, then our set of equations is represented by $Va = y$. The determinant of $V$, when square, is known: $|V| = \prod_{i < j} (x_j - x_i)$.</p><p>That this is non-zero says that there will be a unique solution $a$ for a given $y$ â€“ an alternate proof of the t</p><h3>Divided differences 6.2</h3><p>Suppose we have $y_i = f(x_i)$ and we want to find the interpolating polynomial. We can express this in terms of $f$.</p><p>Following the book (p328), we define</p>$$~
q_0(x) = 1, \quad q_1(x) = (x - x_0), \quad q_2(x) = (x - x_0)(x-x_1),
...
~$$
<p>Then we have seen for some $c_k$ that $p(x) = \sum_{j=0}^n c_j q_j(x)$</p><p>For $n=2$, from $p(x_i) = f(x_i)$, we see that the $c_i$s satisfy $Lc=f$ where $c = [c_0, c_1, c_2]$ and $f=[f(x_0), f(x_1), f(x_2)$ and $L$ is lower triangular</p>$$~
\begin{bmatrix}
1 & 0 & 0 \\
1 & (x_1-x_0) & 0 \\
1 & (x_2-x_0) & (x_2-x_0)\cdot (x_2 - x_1)
\end{bmatrix}.
~$$
<p>We see that $c_m$ depends on $f(x_0), f(x_1), \dots, f(x_m)$ only and not $f(x_j)$ with $j > m$. The book writes $f[x_0, x_1, \dots, x_m] = c_m$. This defines the notation with square brackets called divided differences.</p><p>Notice:</p><ul>
<li><p>From $1 \cdot c_0 = f(x_0)$ that $f[x_0] = f(x_0)$.</p>
</li>
<li><p>From $f(x_1) = f[x_1] = 1 \cdot c_0  + (x_1-x_0) c_1 = f[x_0] + (x_1 - x_0) f[x_0, x_1]$ that we can solve $f[x_0, x_1] = (f[x_1] -f[x_0])/(x_1 - x_0)$.</p>
</li>
</ul><h3>Thm 1 p330</h3><p>The following recursive formula holds:</p>$$~
f[x_0, x_1, \cdots, x_n] = \frac{f[x_1, \cdots, x_n] -
f[x_0, x_1, \cdots, x_{n-1}]}{x_n - x_0}.
~$$
<p>PF: Let $p_k$ interpolate $f$ at $x_0, x_1, \dots, x_k$ and $q$ interpolate $f$ at $x_1, \dots, x_n$. Then</p>$$~
p_n(x) = q(x) + \frac{x - x_n}{x_n-x_0} \cdot (q(x)  - p_{n-1}(x)). (Why?)
~$$
<p>What is coefficient of $x^n$? The left and right side must be the same. On left hand side it is $f[x_0, \dots x_n]$. On right hand side it is</p>$$~
\frac{1}{x_n-x_0}(f[x_1, \dots, x_n] - f[x_0, \dots, x_{n-1}]).
~$$
<h3>Properties:</h3><blockquote>
<p>Thm 2 p333: can permute $x_i$s.  Sure, by uniqueness of polynomial coefficients.</p>
</blockquote><blockquote>
<p>Thm 3 p333: Let $p$ be a polynomial that interpolates $f$ and $t$ some other point then</p>
</blockquote>$$~
f(t) - p(t) = f[x_0, x_1, \dots, x_n, t] \cdot \prod (t-x_j)
~$$
<p>Why? If $q(x)$ interpolates $f(x)$ at the points <em>and</em> $t$, then $q(t) = f(t)$ and</p>$$~
q(x) = p(x) +  f[x_0, x_1, \dots, x_n, t] \cdot \prod (x - x_j)
~$$
<blockquote>
<p>Thm 4 p333: Divided differences look like <em>derivatives</em>. If $f$ has sufficient derivatives, then if $a < x_0 < x_1 < \dots x_n < b$ there exists $\xi$ in $(a,b)$ with</p>
</blockquote>$$~
f[x_0, x_1, \dots, x_n] = \frac{1}{n!}f^{(n)}(\xi).
~$$
<p>This is the error bound theorem in disguise.</p><h3>Relate to Taylor polynomial</h3><p>In calculus, we have that the tangent line is the limit of the secant line. Here we can view it as the limit of the newton interpolating polynomial between $x_0$ and $x_1$ as $x_1 \rightarrow x_0$:</p><pre class="sourceCode julia">function div_differences(f, xs) 
  if length(xs) == 1
    return f(xs[1])
  else
    return (div_differences(f, xs[2:end]) - div_differences(f,xs[1:end-1]))/(xs[end] - xs[1])
  end
end</pre>
<pre class="output">
div_differences (generic function with 1 method)</pre>

<p>And then if we skin it:</p><pre class="sourceCode julia">Base.getindex(f::T, xs...) where {T <: Function} = div_differences(f, [xs...])
Base.getindex(f::T, xs...) where {T <: SymFunction} = div_differences(f, [xs...])</pre>
<pre class="sourceCode julia">using SymPy
@vars x x0 x1
f(x) = sin(x)
p = f[x0] + f[x0, x1]*(x-x0)</pre>
<div class="well well-sm">
$$\frac{1}{- x_{0} + x_{1}} \left(x - x_{0}\right) \left(- \sin{\left (x_{0} \right )} + \sin{\left (x_{1} \right )}\right) + \sin{\left (x_{0} \right )}$$</div>

<p>And taking a limit:</p><pre class="sourceCode julia">limit(p, x1 => x0)</pre>
<div class="well well-sm">
$$x \cos{\left (x_{0} \right )} - x_{0} \cos{\left (x_{0} \right )} + \sin{\left (x_{0} \right )}$$</div>

<p>Or with a symbolic function</p><pre class="sourceCode julia">u = SymFunction("u")
p = u[x0] + u[x0, x1]*(x-x0)</pre>
<div class="well well-sm">
$$\frac{1}{- x_{0} + x_{1}} \left(x - x_{0}\right) \left(- u{\left (x_{0} \right )} + u{\left (x_{1} \right )}\right) + u{\left (x_{0} \right )}$$</div>

<pre class="sourceCode julia">limit(p, x1 => x0)  # this is u(x_0) + u'(x_0) * (x - x_0)</pre>
<div class="well well-sm">
$$x \left. \frac{d}{d \xi_{1}} u{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=x_{0} }} - x_{0} \left. \frac{d}{d \xi_{1}} u{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=x_{0} }} + u{\left (x_{0} \right )}$$</div>

<p>More generally, we can take more points:</p><pre class="sourceCode julia">@vars x h x0
x1 = x0+h; x2=x0+2h; x3=x0+3h
p = u[x0] + u[x0, x1]*(x-x0) + u[x0, x1, x2]*(x-x0)*(x-x1)+u[x0, x1,x2,x3]*(x-x0) *(x-x1)*(x-x2)</pre>
<div class="well well-sm">
$$u{\left (x_{0} \right )} + \frac{1}{3 h} \left(x - x_{0}\right) \left(- \frac{1}{2 h} \left(- \frac{1}{h} \left(- u{\left (x_{0} \right )} + u{\left (h + x_{0} \right )}\right) + \frac{1}{h} \left(- u{\left (h + x_{0} \right )} + u{\left (2 h + x_{0} \right )}\right)\right) + \frac{1}{2 h} \left(- \frac{1}{h} \left(- u{\left (h + x_{0} \right )} + u{\left (2 h + x_{0} \right )}\right) + \frac{1}{h} \left(- u{\left (2 h + x_{0} \right )} + u{\left (3 h + x_{0} \right )}\right)\right)\right) \left(- 2 h + x - x_{0}\right) \left(- h + x - x_{0}\right) + \frac{1}{2 h} \left(x - x_{0}\right) \left(- \frac{1}{h} \left(- u{\left (x_{0} \right )} + u{\left (h + x_{0} \right )}\right) + \frac{1}{h} \left(- u{\left (h + x_{0} \right )} + u{\left (2 h + x_{0} \right )}\right)\right) \left(- h + x - x_{0}\right) + \frac{1}{h} \left(x - x_{0}\right) \left(- u{\left (x_{0} \right )} + u{\left (h + x_{0} \right )}\right)$$</div>

<pre class="sourceCode julia">limit(p, h=>0)(x0 => 0)  # u(0) + u'(0)x + (1/2) * u''(0)x^2 + (1/6) * u'''(0)x^3</pre>
<div class="well well-sm">
$$\frac{x^{3}}{6} \left. \frac{d^{3}}{d \xi_{1}^{3}}  u{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=0 }} + \frac{x^{2}}{2} \left. \frac{d^{2}}{d \xi_{1}^{2}}  u{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=0 }} + x \left. \frac{d}{d \xi_{1}} u{\left (\xi_{1} \right )} \right|_{\substack{ \xi_{1}=0 }} + u{\left (0 \right )}$$</div>


  </div>
</div>  

</body>
</html>
